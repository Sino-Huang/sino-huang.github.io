<!DOCTYPE html>
<html dir="auto" lang="en">
<head><meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<meta content="index, follow" name="robots"/>
<title>Recent Language Model Technique 2024 | Sukai Huang</title>
<meta content="revision" name="keywords"/>
<meta content="[TOC]

Title: Recent Language Model Technique 2024
Review Date: Thu, Apr 25, 2024
url: https://www.youtube.com/watch?v=kzB23CoZG30
url2: https://www.youtube.com/watch?v=iH-wmtxHunk
url3: https://www.youtube.com/watch?v=o68RRGxAtDo

LLama 3



key modification: grouped query attention (GQA)


key instruction-tuning process:

Their approach to post-training is a combination of supervised fine-tuning (SFT), rejection sampling, proximal policy optimization (PPO), and direct preference optimization (DPO).
The quality of the prompts that are used in SFT and the preference rankings that are used in PPO and DPO has an outsized influence on the performance of aligned models.



fine-tuning tool: torchtune" name="description"/>
<meta content="Sukai Huang" name="author"/>
<link href="https://sino-huang.github.io/posts/recent-language-model-technique-2024/" rel="canonical"/>
<meta content="IFgzhtDTVCjONQMwQsBfuf0ZyHdzUR5WFYzbWsf2Gf8" name="google-site-verification"/>
<link as="style" crossorigin="anonymous" href="/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css" integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet"/>
<link href="https://sino-huang.github.io/favicon.ico" rel="icon"/>
<link href="https://sino-huang.github.io/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="https://sino-huang.github.io/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="https://sino-huang.github.io/apple-touch-icon.png" rel="apple-touch-icon"/>
<link href="https://sino-huang.github.io/safari-pinned-tab.svg" rel="mask-icon"/>
<meta content="#2e2e33" name="theme-color"/>
<meta content="#2e2e33" name="msapplication-TileColor"/>
<link href="https://sino-huang.github.io/posts/recent-language-model-technique-2024/index.xml" rel="alternate" type="application/rss+xml"/>
<link href="https://sino-huang.github.io/posts/recent-language-model-technique-2024/" hreflang="en" rel="alternate"/>
<noscript>
<style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
<style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-TTFTV1EWH5"></script>
<script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-TTFTV1EWH5');
        }
      </script><meta content="https://sino-huang.github.io/posts/recent-language-model-technique-2024/" property="og:url"/>
<meta content="Sukai Huang" property="og:site_name"/>
<meta content="Recent Language Model Technique 2024" property="og:title"/>
<meta content="[TOC]
Title: Recent Language Model Technique 2024 Review Date: Thu, Apr 25, 2024 url: https://www.youtube.com/watch?v=kzB23CoZG30 url2: https://www.youtube.com/watch?v=iH-wmtxHunk url3: https://www.youtube.com/watch?v=o68RRGxAtDo LLama 3 key modification: grouped query attention (GQA)
key instruction-tuning process:
Their approach to post-training is a combination of supervised fine-tuning (SFT), rejection sampling, proximal policy optimization (PPO), and direct preference optimization (DPO). The quality of the prompts that are used in SFT and the preference rankings that are used in PPO and DPO has an outsized influence on the performance of aligned models. fine-tuning tool: torchtune" property="og:description"/>
<meta content="en" property="og:locale"/>
<meta content="website" property="og:type"/>
<meta content="https://sino-huang.github.io/posts/recent-language-model-technique-2024/image-assets/cover.png" property="og:image"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="https://sino-huang.github.io/posts/recent-language-model-technique-2024/image-assets/cover.png" name="twitter:image"/>
<meta content="Recent Language Model Technique 2024" name="twitter:title"/>
<meta content="Sukai's academic blog - storing weekly reports and research paper reviews" name="twitter:description"/>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://sino-huang.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Recent Language Model Technique 2024",
      "item": "https://sino-huang.github.io/posts/recent-language-model-technique-2024/"
    }
  ]
}
</script>
</head>
<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<header class="header">
<nav class="nav">
<div class="logo">
<a accesskey="h" href="https://sino-huang.github.io/" title="Sukai Huang (Alt + H)">Sukai Huang</a>
<div class="logo-switches">
<button accesskey="t" id="theme-toggle" title="(Alt + T)">
<svg fill="none" height="18" id="moon" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
</svg>
<svg fill="none" height="18" id="sun" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<circle cx="12" cy="12" r="5"></circle>
<line x1="12" x2="12" y1="1" y2="3"></line>
<line x1="12" x2="12" y1="21" y2="23"></line>
<line x1="4.22" x2="5.64" y1="4.22" y2="5.64"></line>
<line x1="18.36" x2="19.78" y1="18.36" y2="19.78"></line>
<line x1="1" x2="3" y1="12" y2="12"></line>
<line x1="21" x2="23" y1="12" y2="12"></line>
<line x1="4.22" x2="5.64" y1="19.78" y2="18.36"></line>
<line x1="18.36" x2="19.78" y1="5.64" y2="4.22"></line>
</svg>
</button>
</div>
</div>
<ul id="menu">
<li>
<a href="https://sino-huang.github.io/biography/" title="Biography">
<span>Biography</span>
</a>
</li>
<li>
<a href="https://sino-huang.github.io/archives" title="Archive">
<span>Archive</span>
</a>
</li>
<li>
<a href="https://sino-huang.github.io/tags/" title="Tags">
<span>Tags</span>
</a>
</li>
<li>
<a href="https://sino-huang.github.io/categories/" title="Categories">
<span>Categories</span>
</a>
</li>
<li>
<a accesskey="/" href="https://sino-huang.github.io/search/" title="Search (Alt + /)">
<span>Search</span>
</a>
</li>
</ul>
</nav>
</header>
<main class="main">
<header class="page-header"><div class="breadcrumbs"><a href="https://sino-huang.github.io/">Home</a> » <a href="https://sino-huang.github.io/posts/">Posts</a></div>
<h1>
    Recent Language Model Technique 2024
    <a aria-label="RSS" href="/posts/recent-language-model-technique-2024/index.xml" title="RSS">
<svg fill="none" height="23" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
<path d="M4 11a9 9 0 0 1 9 9"></path>
<path d="M4 4a16 16 0 0 1 16 16"></path>
<circle cx="5" cy="19" r="1"></circle>
</svg>
</a>
</h1>
</header>
<div class="post-content"><p>[TOC]</p>
<ol>
<li>Title: Recent Language Model Technique 2024</li>
<li>Review Date: Thu, Apr 25, 2024</li>
<li>url: <a href="https://www.youtube.com/watch?v=kzB23CoZG30">https://www.youtube.com/watch?v=kzB23CoZG30</a></li>
<li>url2: <a href="https://www.youtube.com/watch?v=iH-wmtxHunk">https://www.youtube.com/watch?v=iH-wmtxHunk</a></li>
<li>url3: <a href="https://www.youtube.com/watch?v=o68RRGxAtDo">https://www.youtube.com/watch?v=o68RRGxAtDo</a></li>
</ol>
<h2 id="llama-3">LLama 3<a aria-hidden="true" class="anchor" hidden="" href="#llama-3">#</a></h2>
<p><img alt="image-20240425125031837" loading="lazy" src="/posts/recent-language-model-technique-2024/image-assets/image-20240425125031837.png"/></p>
<ul>
<li>
<p>key modification: grouped query attention (GQA)</p>
</li>
<li>
<p>key instruction-tuning process:</p>
<ul>
<li>Their approach to post-training is a combination of supervised fine-tuning (SFT), rejection sampling, proximal policy optimization (PPO), and direct preference optimization (DPO).</li>
<li>The quality of the prompts that are used in SFT and the preference rankings that are used in PPO and DPO has an <strong><u><em>outsized influence</em></u></strong> on the performance of aligned models.</li>
</ul>
</li>
<li>
<p>fine-tuning tool: <a href="https://github.com/pytorch/torchtune">torchtune</a></p>
</li>
</ul>
<h3 id="llama-architecture">Llama architecture<a aria-hidden="true" class="anchor" hidden="" href="#llama-architecture">#</a></h3>
<ul>
<li><strong>RMSNorm pre-normalization</strong>: This is a normalization technique used in the model</li>
<li><strong>SwiGLU activation function</strong>: This is the activation function used in the model]</li>
<li><strong>Rotary Position Embedding (RoPE)</strong>:  Llama2 uses a new kind of positional embedding mechanism called Rotary  Position Embedding (RoPE)</li>
</ul>
<h3 id="extra-sampling-and-rejection-sampling">Extra: Sampling and Rejection Sampling<a aria-hidden="true" class="anchor" hidden="" href="#extra-sampling-and-rejection-sampling">#</a></h3>
<p>ref: <a href="https://www.youtube.com/watch?v=9ixzzPQWuAY">https://www.youtube.com/watch?v=9ixzzPQWuAY</a>    (Inverse Transform Sampling)</p>
<p>ref: <a href="https://www.youtube.com/watch?v=OXDqjdVVePY">https://www.youtube.com/watch?v=OXDqjdVVePY</a>    (Accept-Reject Sampling)</p>
<h2 id="grouped-query-attention">Grouped Query Attention<a aria-hidden="true" class="anchor" hidden="" href="#grouped-query-attention">#</a></h2>
<ul>
<li>Purpose: save computational cost</li>
<li>Predecessor architecture: <u><em>Multi-Query Attention</em></u></li>
</ul>
<img alt="image-20240425154324824" src="image-assets/image-20240425154324824.png" style="zoom:33%;"/>
<p><img alt="image-20240425154556029" loading="lazy" src="/posts/recent-language-model-technique-2024/image-assets/image-20240425154556029.png"/></p>
<p><img alt="image-20240425154646875" loading="lazy" src="/posts/recent-language-model-technique-2024/image-assets/image-20240425154646875.png"/></p>
<p><strong>Result</strong></p>
<img alt="image-20240425154750368" src="image-assets/image-20240425154750368.png" style="zoom:33%;"/>
<h2 id="nornet-efficient-high-order-spatial-interaction-with-recursive-gated-convolution">NorNet: Efficient High Order Spatial Interaction with Recursive Gated Convolution<a aria-hidden="true" class="anchor" hidden="" href="#nornet-efficient-high-order-spatial-interaction-with-recursive-gated-convolution">#</a></h2>
<p>ref: <a href="https://arxiv.org/abs/2207.14284">https://arxiv.org/abs/2207.14284</a></p>
<p><img alt="image-20240425223058722" loading="lazy" src="/posts/recent-language-model-technique-2024/image-assets/image-20240425223058722.png"/></p>
<p><img alt="image-20240425223112089" loading="lazy" src="/posts/recent-language-model-technique-2024/image-assets/image-20240425223112089.png"/></p>
<p>Check definition of <strong><u><em>depthwise convolution</em></u></strong>: <a href="https://www.youtube.com/watch?v=vVaRhZXovbw">https://www.youtube.com/watch?v=vVaRhZXovbw</a></p>
<p><img alt="image-20240425223355380" loading="lazy" src="/posts/recent-language-model-technique-2024/image-assets/image-20240425223355380.png"/></p>
<h2 id="capability-forgetting-from-glm-4">Capability Forgetting (from GLM-4)<a aria-hidden="true" class="anchor" hidden="" href="#capability-forgetting-from-glm-4">#</a></h2>
<p>as a post-training step subsequent to SFT, the author also observed unexpected behaviour in the policy after the RLHF stage. The model shows a <strong><u>reduced capability</u></strong> in handling specific scenarios.</p>
<ul>
<li>reason
<ul>
<li>this behavior could be attributed to the problem of difference among data distributions or the inability of the reward model in such nuanced details.</li>
</ul>
</li>
<li>solution
<ul>
<li>to overcome, the author incorporate an extra supervised next token prediction loss as an additional regularization besides the KL divergence. (in PPO)</li>
<li>this is intended to preserve the pre-existing abilities of the SFT model, by encouraging the model’s outputs to align with human preferences through RLHF and leveraging next-token prediction to capture more granular signals.</li>
<li>the next token prediction with a small amount of human-annotated (prompt, response) pairs $\mathcal{D}_S$, which are specific to particular tasks and serve as supervised regularization (trying to shifting the data distribution back)</li>
</ul>
</li>
</ul>
<h2 id="direct-preference-optimization">Direct Preference Optimization<a aria-hidden="true" class="anchor" hidden="" href="#direct-preference-optimization">#</a></h2>
<p>can we just use Cross entropy instead of PPO?</p>
<p><img alt="image-20240426231336360" loading="lazy" src="/posts/recent-language-model-technique-2024/image-assets/image-20240426231336360.png"/></p>
<p><img alt="image-20240426232104891" loading="lazy" src="/posts/recent-language-model-technique-2024/image-assets/image-20240426232104891.png"/></p>
</div>
</main>
<footer class="footer">
<span>© 2024 <a href="https://sino-huang.github.io/">Sukai Huang</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &amp;
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
</span>
</footer>
<a accesskey="g" aria-label="go to top" class="top-link" href="#top" id="top-link" title="Go to Top (Alt + G)">
<svg fill="currentColor" viewbox="0 0 12 6" xmlns="http://www.w3.org/2000/svg">
<path d="M12 6H0l6-6z"></path>
</svg>
</a>
<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>
</html>
