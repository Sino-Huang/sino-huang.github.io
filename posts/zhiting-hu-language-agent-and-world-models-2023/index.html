<!DOCTYPE html>
<html dir="auto" lang="en">
<head><meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<meta content="index, follow" name="robots"/>
<title>Zhiting Hu Language Agent and World Models 2023 | Sukai Huang</title>
<meta content="llm agent" name="keywords"/>
<meta content="[TOC]

Title: Zhiting Hu Language Agent and World Models 2023
Author:
Publish Year:
Review Date: Mon, Jan 22, 2024
url: arXiv:2312.05230v1

Summary of paper

Motivation

LAW proposes that world and agent models, which encompass beliefs about  the world, anticipation of consequences, goals/rewards, and strategic  planning, provide a better abstraction of reasoning. In this framework,  language models play a crucial role as a backend

Some key terms
Limitation of Language" name="description"/>
<meta content="Sukai Huang" name="author"/>
<link href="https://sino-huang.github.io/posts/zhiting-hu-language-agent-and-world-models-2023/" rel="canonical"/>
<meta content="IFgzhtDTVCjONQMwQsBfuf0ZyHdzUR5WFYzbWsf2Gf8" name="google-site-verification"/>
<link as="style" crossorigin="anonymous" href="/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css" integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet"/>
<link href="https://sino-huang.github.io/favicon.ico" rel="icon"/>
<link href="https://sino-huang.github.io/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="https://sino-huang.github.io/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="https://sino-huang.github.io/apple-touch-icon.png" rel="apple-touch-icon"/>
<link href="https://sino-huang.github.io/safari-pinned-tab.svg" rel="mask-icon"/>
<meta content="#2e2e33" name="theme-color"/>
<meta content="#2e2e33" name="msapplication-TileColor"/>
<link href="https://sino-huang.github.io/posts/zhiting-hu-language-agent-and-world-models-2023/index.xml" rel="alternate" type="application/rss+xml"/>
<link href="https://sino-huang.github.io/posts/zhiting-hu-language-agent-and-world-models-2023/" hreflang="en" rel="alternate"/>
<noscript>
<style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
<style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-TTFTV1EWH5"></script>
<script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-TTFTV1EWH5');
        }
      </script><meta content="https://sino-huang.github.io/posts/zhiting-hu-language-agent-and-world-models-2023/" property="og:url"/>
<meta content="Sukai Huang" property="og:site_name"/>
<meta content="Zhiting Hu Language Agent and World Models 2023" property="og:title"/>
<meta content="[TOC]
Title: Zhiting Hu Language Agent and World Models 2023 Author: Publish Year: Review Date: Mon, Jan 22, 2024 url: arXiv:2312.05230v1 Summary of paper Motivation LAW proposes that world and agent models, which encompass beliefs about the world, anticipation of consequences, goals/rewards, and strategic planning, provide a better abstraction of reasoning. In this framework, language models play a crucial role as a backend Some key terms Limitation of Language" property="og:description"/>
<meta content="en" property="og:locale"/>
<meta content="website" property="og:type"/>
<meta content="https://sino-huang.github.io/posts/zhiting-hu-language-agent-and-world-models-2023/image-assets/cover.png" property="og:image"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="https://sino-huang.github.io/posts/zhiting-hu-language-agent-and-world-models-2023/image-assets/cover.png" name="twitter:image"/>
<meta content="Zhiting Hu Language Agent and World Models 2023" name="twitter:title"/>
<meta content="Sukai's academic blog - storing weekly reports and research paper reviews" name="twitter:description"/>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://sino-huang.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Zhiting Hu Language Agent and World Models 2023",
      "item": "https://sino-huang.github.io/posts/zhiting-hu-language-agent-and-world-models-2023/"
    }
  ]
}
</script>
</head>
<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<header class="header">
<nav class="nav">
<div class="logo">
<a accesskey="h" href="https://sino-huang.github.io/" title="Sukai Huang (Alt + H)">Sukai Huang</a>
<div class="logo-switches">
<button accesskey="t" id="theme-toggle" title="(Alt + T)">
<svg fill="none" height="18" id="moon" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
</svg>
<svg fill="none" height="18" id="sun" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<circle cx="12" cy="12" r="5"></circle>
<line x1="12" x2="12" y1="1" y2="3"></line>
<line x1="12" x2="12" y1="21" y2="23"></line>
<line x1="4.22" x2="5.64" y1="4.22" y2="5.64"></line>
<line x1="18.36" x2="19.78" y1="18.36" y2="19.78"></line>
<line x1="1" x2="3" y1="12" y2="12"></line>
<line x1="21" x2="23" y1="12" y2="12"></line>
<line x1="4.22" x2="5.64" y1="19.78" y2="18.36"></line>
<line x1="18.36" x2="19.78" y1="5.64" y2="4.22"></line>
</svg>
</button>
</div>
</div>
<ul id="menu">
<li>
<a href="https://sino-huang.github.io/biography/" title="Biography">
<span>Biography</span>
</a>
</li>
<li>
<a href="https://sino-huang.github.io/archives" title="Archive">
<span>Archive</span>
</a>
</li>
<li>
<a href="https://sino-huang.github.io/tags/" title="Tags">
<span>Tags</span>
</a>
</li>
<li>
<a href="https://sino-huang.github.io/categories/" title="Categories">
<span>Categories</span>
</a>
</li>
<li>
<a accesskey="/" href="https://sino-huang.github.io/search/" title="Search (Alt + /)">
<span>Search</span>
</a>
</li>
</ul>
</nav>
</header>
<main class="main">
<header class="page-header"><div class="breadcrumbs"><a href="https://sino-huang.github.io/">Home</a> » <a href="https://sino-huang.github.io/posts/">Posts</a></div>
<h1>
    Zhiting Hu Language Agent and World Models 2023
    <a aria-label="RSS" href="/posts/zhiting-hu-language-agent-and-world-models-2023/index.xml" title="RSS">
<svg fill="none" height="23" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
<path d="M4 11a9 9 0 0 1 9 9"></path>
<path d="M4 4a16 16 0 0 1 16 16"></path>
<circle cx="5" cy="19" r="1"></circle>
</svg>
</a>
</h1>
</header>
<div class="post-content"><p>[TOC]</p>
<ol>
<li>Title: Zhiting Hu Language Agent and World Models 2023</li>
<li>Author:</li>
<li>Publish Year:</li>
<li>Review Date: Mon, Jan 22, 2024</li>
<li>url: arXiv:2312.05230v1</li>
</ol>
<h2 id="summary-of-paper">Summary of paper<a aria-hidden="true" class="anchor" hidden="" href="#summary-of-paper">#</a></h2>
<p><img alt="image-20240122201639803" loading="lazy" src="/posts/zhiting-hu-language-agent-and-world-models-2023/image-assets/cover.png"/></p>
<h3 id="motivation">Motivation<a aria-hidden="true" class="anchor" hidden="" href="#motivation">#</a></h3>
<ul>
<li>LAW proposes that world and agent models, which encompass beliefs about  the world, anticipation of consequences, goals/rewards, and strategic  planning, provide a better abstraction of reasoning. In this framework,  language models play a crucial role as a backend</li>
</ul>
<h3 id="some-key-terms">Some key terms<a aria-hidden="true" class="anchor" hidden="" href="#some-key-terms">#</a></h3>
<p><strong>Limitation of Language</strong></p>
<ul>
<li>Ambiguity and Imprecision: LLMs struggle with natural language’s ambiguity and imprecision because they lack the rich context that humans use when producing text. This context includes perceptual, social, and mental factors, as well as world commonsense. LLMs simulate surface text without understanding underlying context, leading to limitations in grounding on physical, social, and mental experiences.</li>
<li>Inefficiency of Language: LLMs face challenges when using language as the primary medium for reasoning, especially in situations requiring nuanced descriptions. For instance, describing subtle differences between two objects might require lengthy text, while generating an image or using other sensory modalities can be more efficient for certain tasks, such as predicting fluid flow based on physical properties.</li>
</ul>
<p><strong>Failure case</strong></p>
<p><img alt="image-20240122201312942" loading="lazy" src="/posts/zhiting-hu-language-agent-and-world-models-2023/image-assets/image-20240122201312942.png"/></p>
<p><strong>System-II reasoning – construct a mental model of the world</strong></p>
<ul>
<li>for robust reasoning during complex tasks (Tolman, 1948; Briscoe, 2011;)</li>
<li>The paper outlines the background of these three models (language,  agent, world models), then introduces the LAW (Language, Agent, World)  framework for reasoning. It reviews recent studies related to each  element in the framework and discusses the roadmap for addressing the  challenges and advancing machine reasoning and planning.</li>
</ul>
<p><strong>Two levels of agent model</strong></p>
<p>There are two levels of agent models:</p>
<ol>
<li>Level-0 Agent Models: These models represent how an embodied agent optimizes actions to maximize accumulated rewards based on belief and the physical constraints defined in its world model. They are used in embodied tasks, such as a robot searching for a cup.</li>
<li>Level-1 Agent Models: These models are used in social reasoning tasks and involve reasoning about the behaviors of other agents. They encompass Theory of Mind, which means forming mental models of other agents and conducting causal reasoning to interpret their behaviors based on their mental states like goals and beliefs.</li>
</ol>
<p><strong>LAW framework structure</strong></p>
<p>The paper reviews recent works relevant to the LAW framework, highlighting several approaches:</p>
<ol>
<li>LMs as Both World and Agent Models (Reasoning-via-Planning, or RAP): LMs are repurposed to serve as world models by predicting future states in reasoning and as agent models by generating actions. This approach allows for reasoning traces that consist of interleaved states and reasoning steps, improving inference coherence. RAP incorporates Monte Carlo Tree Search (MCTS) for strategic exploration in reasoning.</li>
<li>Probabilistic Programs: Probabilistic programs are used to construct world and agent models for physical and social reasoning. LMs are employed to translate natural language descriptions into probabilistic programs, serving as an interface between language and thought.</li>
<li>LMs as the Planner in Agent Models: LMs are used to generate plans based on prompts specifying the state, task, and memory. Interactive planning paradigms provide feedback and reflection on past actions to adjust future plans. LMs can also simulate social behaviors in abstract environments, enhancing social reasoning.</li>
<li>LMs as the Goal/Reward in Agent Models: LMs are considered for generating goals or rewards in agent models. They can translate language descriptions of intended tasks into goal and reward specifications, simplifying the process.</li>
<li>LMs as the Belief in Agent Models: Although less explored, there is potential for using LMs to explicitly model belief representations in agent models, similar to their role as planners, goals, or rewards.</li>
</ol>
<h2 id="results">Results<a aria-hidden="true" class="anchor" hidden="" href="#results">#</a></h2>
<p>However, the authors acknowledge certain <strong>limitations</strong> of the LAW framework:</p>
<ol>
<li>Symbolic Representations: The language model backend relies on symbolic representations in a discrete space. While there’s potential to augment this space with continuous latent spaces from other modalities, it remains unclear whether a single continuous latent space can achieve similar capacity as symbolic representations.</li>
<li>Incomplete Modeling: The current world and agent modeling may not capture all knowledge about the world and agents. For example, it assumes that agent behaviors are primarily driven by goals or rewards, overlooking other potential factors like social norms.</li>
<li>Transformer Architecture Limits: The paper does not delve into the inherent limits of Transformer architectures, which are foundational to many language models. Further research into understanding the learning mechanisms of Transformers may complement the development of machine reasoning.</li>
</ol>
<p>Overall, while the LAW framework presents a promising direction for advancing machine reasoning, it is essential to address these limitations and continue exploring ways to enhance its capabilities.</p>
<h2 id="summary">Summary<a aria-hidden="true" class="anchor" hidden="" href="#summary">#</a></h2>
<p>This is a discussion paper</p>
</div>
</main>
<footer class="footer">
<span>© 2024 <a href="https://sino-huang.github.io/">Sukai Huang</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &amp;
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
</span>
</footer>
<a accesskey="g" aria-label="go to top" class="top-link" href="#top" id="top-link" title="Go to Top (Alt + G)">
<svg fill="currentColor" viewbox="0 0 12 6" xmlns="http://www.w3.org/2000/svg">
<path d="M12 6H0l6-6z"></path>
</svg>
</a>
<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>
</html>
