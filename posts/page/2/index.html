<!DOCTYPE html>
<html dir="auto" lang="en">
<head><meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<meta content="index, follow" name="robots"/>
<title>Posts | Sukai Huang</title>
<meta content="" name="keywords"/>
<meta content="Posts - Sukai Huang" name="description"/>
<meta content="Sukai Huang" name="author"/>
<link href="https://sino-huang.github.io/posts/" rel="canonical"/>
<meta content="IFgzhtDTVCjONQMwQsBfuf0ZyHdzUR5WFYzbWsf2Gf8" name="google-site-verification"/>
<link as="style" crossorigin="anonymous" href="/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css" integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet"/>
<link href="https://sino-huang.github.io/favicon.ico" rel="icon"/>
<link href="https://sino-huang.github.io/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="https://sino-huang.github.io/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="https://sino-huang.github.io/apple-touch-icon.png" rel="apple-touch-icon"/>
<link href="https://sino-huang.github.io/safari-pinned-tab.svg" rel="mask-icon"/>
<meta content="#2e2e33" name="theme-color"/>
<meta content="#2e2e33" name="msapplication-TileColor"/>
<link href="https://sino-huang.github.io/posts/index.xml" rel="alternate" type="application/rss+xml"/>
<link href="https://sino-huang.github.io/posts/" hreflang="en" rel="alternate"/>
<noscript>
<style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
<style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.16.18/dist/katex.min.css" integrity="sha384-veTAhWILPOotXm+kbR5uY7dRamYLJf58I7P+hJhjeuc7hsMAkJHTsPahAl0hBST0" rel="stylesheet"/>
<script crossorigin="anonymous" defer="" integrity="sha384-v6mkHYHfY/4BWq54f7lQAdtIsoZZIByznQ3ZqN38OL4KCsrxo31SLlPiak7cj/Mg" src="https://cdn.jsdelivr.net/npm/katex@0.16.18/dist/katex.min.js"></script>
<script crossorigin="anonymous" defer="" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" src="https://cdn.jsdelivr.net/npm/katex@0.16.18/dist/contrib/auto-render.min.js"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-TTFTV1EWH5"></script>
<script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-TTFTV1EWH5');
        }
      </script><meta content="https://sino-huang.github.io/posts/" property="og:url"/>
<meta content="Sukai Huang" property="og:site_name"/>
<meta content="Posts" property="og:title"/>
<meta content="Sukai's academic blog - storing weekly reports and research paper reviews" property="og:description"/>
<meta content="en" property="og:locale"/>
<meta content="website" property="og:type"/>
<meta content="https://sino-huang.github.io/cute_avatar.jpg" property="og:image"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="https://sino-huang.github.io/cute_avatar.jpg" name="twitter:image"/>
<meta content="Posts" name="twitter:title"/>
<meta content="Sukai's academic blog - storing weekly reports and research paper reviews" name="twitter:description"/>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://sino-huang.github.io/posts/"
    }
  ]
}
</script>
</head>
<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<header class="header">
<nav class="nav">
<div class="logo">
<a accesskey="h" href="https://sino-huang.github.io/" title="Sukai Huang (Alt + H)">Sukai Huang</a>
<div class="logo-switches">
<button accesskey="t" id="theme-toggle" title="(Alt + T)">
<svg fill="none" height="18" id="moon" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
</svg>
<svg fill="none" height="18" id="sun" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<circle cx="12" cy="12" r="5"></circle>
<line x1="12" x2="12" y1="1" y2="3"></line>
<line x1="12" x2="12" y1="21" y2="23"></line>
<line x1="4.22" x2="5.64" y1="4.22" y2="5.64"></line>
<line x1="18.36" x2="19.78" y1="18.36" y2="19.78"></line>
<line x1="1" x2="3" y1="12" y2="12"></line>
<line x1="21" x2="23" y1="12" y2="12"></line>
<line x1="4.22" x2="5.64" y1="19.78" y2="18.36"></line>
<line x1="18.36" x2="19.78" y1="5.64" y2="4.22"></line>
</svg>
</button>
</div>
</div>
<ul id="menu">
<li>
<a href="https://sino-huang.github.io/biography/" title="Biography">
<span>Biography</span>
</a>
</li>
<li>
<a href="https://sino-huang.github.io/archives" title="Archive">
<span>Archive</span>
</a>
</li>
<li>
<a href="https://sino-huang.github.io/tags/" title="Tags">
<span>Tags</span>
</a>
</li>
<li>
<a href="https://sino-huang.github.io/categories/" title="Categories">
<span>Categories</span>
</a>
</li>
<li>
<a accesskey="/" href="https://sino-huang.github.io/search/" title="Search (Alt + /)">
<span>Search</span>
</a>
</li>
</ul>
</nav>
</header>
<main class="main">
<header class="page-header"><div class="breadcrumbs"><a href="https://sino-huang.github.io/">Home</a></div>
<h1>
    Posts
    <a aria-label="RSS" href="/posts/index.xml" title="RSS">
<svg fill="none" height="23" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
<path d="M4 11a9 9 0 0 1 9 9"></path>
<path d="M4 4a16 16 0 0 1 16 16"></path>
<circle cx="5" cy="19" r="1"></circle>
</svg>
</a>
</h1>
</header>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/avichai-levy-understanding-natural-language-in-context-2023/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Avichai Levy Understanding Natural Language in Context 2023
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Understanding Natural Language in Context Author: Avichai Levy et. al. Publish Year: ICAPS 2023 Review Date: Mon, Jan 29, 2024 url: https://ojs.aaai.org/index.php/ICAPS/article/view/27248 Summary of paper Contribution The paper discusses the increasing prevalence of applications with natural language interfaces, such as chatbots and personal assistants like Alexa, Google Assistant, Siri, and Cortana. While current dialogue systems mainly involve static robots, the challenge intensifies with cognitive robots capable of movement and object manipulation in home environments. The focus is on cognitive robots equipped with knowledge-based models of the world, enabling reasoning and planning. The paper proposes an approach to translate natural language directives into the robot’s formalism, leveraging state-of-the-art large language models, planning tools, and the robot’s knowledge of the world and its own model. This approach enhances the interpretation of directives in natural language, facilitating the completion of complex household tasks.
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-29 20:25:43 +1100 AEDT">January 29, 2024</span> · 3 min · 477 words · Sukai Huang</footer>
<a aria-label="post link to Avichai Levy Understanding Natural Language in Context 2023" class="entry-link" href="https://sino-huang.github.io/posts/avichai-levy-understanding-natural-language-in-context-2023/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/mingyu-jin-the-impact-of-reasoning-steps-length-on-llm-2024/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Mingyu Jin the Impact of Reasoning Steps Length on Llm 2024
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: The Impact of Reasoning Steps Length on Large Language Models Author: Mingyu Jin et. al. Publish Year: 20 Jan 2024 Review Date: Mon, Jan 29, 2024 url: arXiv:2401.04925v3 Summary of paper Contribution The study investigates the impact of the length of reasoning steps in prompts on the reasoning abilities of Large Language Models (LLMs), focusing on Chain of Thought (CoT). Here are the key findings:
Effect of Reasoning Step Length:
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-29 17:44:10 +1100 AEDT">January 29, 2024</span> · 3 min · 568 words · Sukai Huang</footer>
<a aria-label="post link to Mingyu Jin the Impact of Reasoning Steps Length on Llm 2024" class="entry-link" href="https://sino-huang.github.io/posts/mingyu-jin-the-impact-of-reasoning-steps-length-on-llm-2024/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/collin-burns-weak-to-strong-generalisation-weak-supervision-2023/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Weak-To-Strong-Generalization: Eliciting Strong Capabilities with Weak Supervision
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Weak-To-Strong-Generalization: Eliciting Strong Capabilities with Weak Supervision Author: Collin Burns et. al. Publish Year: 14 Dec 2023 Review Date: Mon, Jan 29, 2024 url: arXiv:2312.09390v1 Summary of paper Motivation Superalignment: OPENAI believe that RLHF is essentially use human to supervise the model (RM is trained by human annotation). One day when superhuman models come out, human are no longer to annotate the good / bad of the model’s output. e.g., superhuman model generate a 1M lines complex code and human cannot review it. How to do the alignment in for this case? thus the research question is can we use a weak teacher model to improve strong student model Contribution they used weak model to generate annotations and fine tune the strong model, they empirically did a lot of experiments note: although they use the term teacher and student, the alignment task is not about “teaching”, alignment is to elicit learnt stuffs from strong foundation model (something like finetuning), rather than asking strong model to follow weak teacher model. Some key terms Bootstrapping
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-29 15:32:21 +1100 AEDT">January 29, 2024</span> · 2 min · 377 words · Sukai Huang</footer>
<a aria-label="post link to Weak-To-Strong-Generalization: Eliciting Strong Capabilities with Weak Supervision" class="entry-link" href="https://sino-huang.github.io/posts/collin-burns-weak-to-strong-generalisation-weak-supervision-2023/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/ziwei-xu-hallucination-is-inevitable-an-innate-limitation-llm-2024/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Ziwei Xu Hallucination Is Inevitable an Innate Limitation Llm 2024
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Hallucination Is Inevitable an Innate Limitation Llm 2024 Author: Ziwei Xu et. al. Publish Year: 22 Jan 2024 Review Date: Sun, Jan 28, 2024 url: arXiv:2401.11817v1 Summary of paper Contribution The paper formalizes the issue of hallucination in large language models (LLMs) and argues that it is impossible to completely eliminate hallucination. It defines hallucination as inconsistencies between a computable LLM and a computable ground truth function. By drawing from learning theory, the paper demonstrates that LLMs cannot learn all computable functions, thus always prone to hallucination. The formal world is deemed a simplified representation of the real world, implying that hallucination is inevitable for real-world LLMs. Additionally, for real-world LLMs with provable time complexity constraints, the paper identifies tasks prone to hallucination and provides empirical validation. Finally, the paper evaluates existing hallucination mitigators using the formal world framework and discusses practical implications for the safe deployment of LLMs.
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-28 23:11:28 +1100 AEDT">January 28, 2024</span> · 3 min · 543 words · Sukai Huang</footer>
<a aria-label="post link to Ziwei Xu Hallucination Is Inevitable an Innate Limitation Llm 2024" class="entry-link" href="https://sino-huang.github.io/posts/ziwei-xu-hallucination-is-inevitable-an-innate-limitation-llm-2024/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/zhiwei-he-improving-machine-translation-use-quality-estimation-as-a-reward-model-2024/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Zhiwei He Improving Machine Translation Use Quality Estimation as a Reward Model 2024
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Improving Machine Translation Use Quality Estimation as a Reward Model 2024 Author: Zhiwei He et. al. Publish Year: 23 Jan 2024 Review Date: Sun, Jan 28, 2024 url: arXiv:2401.12873v1 Summary of paper Contribution In this research, the authors explore using Quality Estimation (QE) models as a basis for reward systems in translation quality improvement through human feedback. They note that while QE has shown promise aligning with human evaluations, there’s a risk of overoptimization where translations receive high rewards despite declining quality. The study addresses this by introducing heuristic rules to identify and penalize incorrect translations, resulting in improved training outcomes. Experimental results demonstrate consistent enhancements across various setups, validated by human preference studies. Additionally, the approach proves highly data-efficient, outperforming systems relying on larger parallel corpora with only a small amount of monolingual data.
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-28 22:53:41 +1100 AEDT">January 28, 2024</span> · 2 min · 285 words · Sukai Huang</footer>
<a aria-label="post link to Zhiwei He Improving Machine Translation Use Quality Estimation as a Reward Model 2024" class="entry-link" href="https://sino-huang.github.io/posts/zhiwei-he-improving-machine-translation-use-quality-estimation-as-a-reward-model-2024/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/krishan-rana-sayplan-grounding-llm-for-scalable-task-planning-2023/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Krishan Rana Sayplan Grounding Llm for Scalable Task Planning 2023
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: SayPlan: Grounding Large Language Models using 3D Scene for for Scalable Task Planning Author: Krishan Rana Publish Year: CoRL 2023 Review Date: Sun, Jan 28, 2024 url: https://arxiv.org/abs/2307.06135 Summary of paper Motivation this is a pipeline introduction paper Contribution Hierarchical Exploration: SayPlan leverages the hierarchical structure of 3DSGs to enable LLMs to conduct semantic searches for task-relevant subgraphs from a condensed representation of the full graph. Path Planning Integration: It integrates a classical path planner to reduce the planning horizon for the LLM, thus improving efficiency. Iterative Replanning Pipeline: An iterative replanning pipeline refines initial plans by incorporating feedback from a scene graph simulator, correcting infeasible actions and preventing planning failures. Some key terms ...</p>
</div>
<footer class="entry-footer"><span title="2024-01-28 21:37:21 +1100 AEDT">January 28, 2024</span> · 2 min · 388 words · Sukai Huang</footer>
<a aria-label="post link to Krishan Rana Sayplan Grounding Llm for Scalable Task Planning 2023" class="entry-link" href="https://sino-huang.github.io/posts/krishan-rana-sayplan-grounding-llm-for-scalable-task-planning-2023/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/luigi-bonassi-planning-with-qualitative-constraints-pddl3-2022/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Luigi Bonassi Planning With Qualitative Constraints Pddl3 2022
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Planning With Qualitative Constraints Pddl3 2022 Author: Luigi Bonassi et. al. Publish Year: Review Date: Sun, Jan 28, 2024 url: https://www.ijcai.org/proceedings/2022/0639.pdf Summary of paper The paper introduces a formalism to express trajectory constraints over actions in plans, complementing the state-trajectory constraints of PDDL3. This new formalism retains PDDL3’s temporal modal operators and adds two modalities. The authors then explore compilation-based methods for dealing with action-trajectory constraints in propositional planning, proposing a new, simple, and effective method. Experimental results demonstrate the utility of action-trajectory constraints for expressing control knowledge, showing significant performance improvements in classical planners when leveraging knowledge expressed through action constraints. Conversely, the same knowledge specified as state constraints and handled by two state-of-the-art systems yields less beneficial results.
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-28 21:28:51 +1100 AEDT">January 28, 2024</span> · 1 min · 125 words · Sukai Huang</footer>
<a aria-label="post link to Luigi Bonassi Planning With Qualitative Constraints Pddl3 2022" class="entry-link" href="https://sino-huang.github.io/posts/luigi-bonassi-planning-with-qualitative-constraints-pddl3-2022/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/parsa-mahmoudieh-zero-shot-reward-specification-via-grounded-natural-language-2022/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Parsa Mahmoudieh Zero Shot Reward Specification via Grounded Natural Language 2022
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Zero Shot Reward Specification via Grounded Natural Language Author: Parsa Mahnoudieh et. al. Publish Year: PMLR 2022 Review Date: Sun, Jan 28, 2024 url: Summary of paper Motivation reward signals in RL are expensive to design and often require access to the true state. common alternatives are usually demonstrations or goal images which can be label intensive on the other hand, text descriptions provide a general low-effect way of communicating. previous work rely on true state or labelled expert demonstration match, this work directly use CLIP to convert the observation to semantic embeddings Contribution Some key terms Difference
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-28 09:31:05 +1100 AEDT">January 28, 2024</span> · 3 min · 538 words · Sukai Huang</footer>
<a aria-label="post link to Parsa Mahmoudieh Zero Shot Reward Specification via Grounded Natural Language 2022" class="entry-link" href="https://sino-huang.github.io/posts/parsa-mahmoudieh-zero-shot-reward-specification-via-grounded-natural-language-2022/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/allen-z-ren-robots-that-ask-for-help-uncertainty-alignment-2023/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Allen Z Ren Robots That Ask for Help Uncertainty Alignment 2023
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Robots That Ask for Help: Uncertainty Alignment for Large Language Model Planners Author: Allen Z. Ren et. al. Publish Year: 4 Sep 2023 Review Date: Fri, Jan 26, 2024 url: arXiv:2307.01928v2 Summary of paper Motivation LLMs have various capabilities but often make overly confident yet incorrect predictions. KNOWNO aims to measure and align this uncertainty, enabling LLM-based planners to recognize their limitations and request assistance when necessary. Contribution built on theory of conformal prediction Some key terms Ambiguity in NL
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-26 17:29:29 +1100 AEDT">January 26, 2024</span> · 3 min · 510 words · Sukai Huang</footer>
<a aria-label="post link to Allen Z Ren Robots That Ask for Help Uncertainty Alignment 2023" class="entry-link" href="https://sino-huang.github.io/posts/allen-z-ren-robots-that-ask-for-help-uncertainty-alignment-2023/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/marta-skreta-replan-robotic-replanning-2024/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Marta Skreta Replan Robotic Replanning 2024
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: RePlan: Robotic Replanning with Perception and Language Models Author: Marta Skreta et. al. Publish Year: 8 Jan 2024 Review Date: Thu, Jan 25, 2024 url: arXiv:2401.04157v1 Summary of paper Motivation However, the challenge remains that even with syntac- tically correct plans, robots can still fail to achieve their intended goals. This failure can be attributed to imperfect plans proposed by LLMs or to unforeseeable environmental circumstances that hinder the execution of planned subtasks due to erroneous assumptions about the state of objects. Contribution Robotic Replanning with Perception and Language Models that enables real-time replanning capabilities for long-horizon tasks. Some key terms Address the challenge of multi-stage long-horizon tasks
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-25 00:55:05 +1100 AEDT">January 25, 2024</span> · 2 min · 261 words · Sukai Huang</footer>
<a aria-label="post link to Marta Skreta Replan Robotic Replanning 2024" class="entry-link" href="https://sino-huang.github.io/posts/marta-skreta-replan-robotic-replanning-2024/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/binghai-wang-secrets-of-rlhf-reward-modelling-2024/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Binghai Wang Secrets of Rlhf Reward Modelling 2024
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Secrets of RLHF in Large Language Models Part II: Reward Modelling Author: Binghai Wang et. al. Publish Year: 12 Jan 2024 Review Date: Wed, Jan 24, 2024 url: arXiv:2401.06080v2 Summary of paper Motivation a crucial technology for aligning language models with human values. Two main issues are tackled: (1) Incorrect and ambiguous preference pairs in the dataset hindering reward model accuracy, and (2) Difficulty in generalization for reward models trained on specific distributions. a method measuring preference strength within the data is proposed, utilizing a voting mechanism of multiple reward models. Novel techniques are introduced to mitigate the impact of incorrect preferences and leverage high-quality preference data. For the second issue, contrastive learning is introduced to enhance the reward models’ ability to distinguish between chosen and rejected responses, improving generalization. Some key terms noisy data
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-24 23:31:28 +1100 AEDT">January 24, 2024</span> · 1 min · 144 words · Sukai Huang</footer>
<a aria-label="post link to Binghai Wang Secrets of Rlhf Reward Modelling 2024" class="entry-link" href="https://sino-huang.github.io/posts/binghai-wang-secrets-of-rlhf-reward-modelling-2024/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/rui-zheng-secrets-of-rlhf-in-llm-part-ppo-2023/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Rui Zheng Secrets of Rlhf in Llm Part Ppo 2023
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Secrets of RLHF in Large Language Models Part1: PPO Author: Rui Zheng et. al. Publish Year: 18 Jul 2023 Review Date: Mon, Jan 22, 2024 url: arXiv:2307.04964v2 Summary of paper Motivation Current approaches involve creating reward models to measure human preferences, using Proximal Policy Optimization (PPO) to improve policy models, and enhancing step-by-step reasoning through process supervision. However, challenges in reward design, interaction with the environment, and agent training, along with the high trial and error costs of LLMs, make it difficult for researchers to develop technically aligned and safe LLMs. Contribution finding that LLMs trained using their algorithm can better understand query meanings and provide responses that resonate with people. A new PPO algorithm called PPO-max is introduced, which incorporates effective implementations and addresses stability issues. Some key terms RLHF limitation
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-22 20:26:18 +1100 AEDT">January 22, 2024</span> · 3 min · 465 words · Sukai Huang</footer>
<a aria-label="post link to Rui Zheng Secrets of Rlhf in Llm Part Ppo 2023" class="entry-link" href="https://sino-huang.github.io/posts/rui-zheng-secrets-of-rlhf-in-llm-part-ppo-2023/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/zhiting-hu-language-agent-and-world-models-2023/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Zhiting Hu Language Agent and World Models 2023
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Zhiting Hu Language Agent and World Models 2023 Author: Publish Year: Review Date: Mon, Jan 22, 2024 url: arXiv:2312.05230v1 Summary of paper Motivation LAW proposes that world and agent models, which encompass beliefs about the world, anticipation of consequences, goals/rewards, and strategic planning, provide a better abstraction of reasoning. In this framework, language models play a crucial role as a backend Some key terms Limitation of Language
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-22 16:01:20 +1100 AEDT">January 22, 2024</span> · 4 min · 749 words · Sukai Huang</footer>
<a aria-label="post link to Zhiting Hu Language Agent and World Models 2023" class="entry-link" href="https://sino-huang.github.io/posts/zhiting-hu-language-agent-and-world-models-2023/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/gautier-dagan-dynamic-planning-with-a-llm-2023/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Gautier Dagan Dynamic Planning With a Llm 2023
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Dynamic Planning With a LLM Author: Gautier Dagan et. al. Publish Year: 11 Aug 2023 Review Date: Sun, Jan 21, 2024 url: arXiv:2308.06391v1 Summary of paper Motivation Traditional symbolic planners can find optimal solutions quickly but need complete and accurate problem representations. In contrast, LLMs can handle noisy data and uncertainty but struggle with planning tasks. The LLM-DP framework combines LLMs and traditional planners to solve embodied tasks efficiently. Traditional Planner need maximal information Some key terms Hallucination
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-21 01:42:23 +1100 AEDT">January 21, 2024</span> · 2 min · 384 words · Sukai Huang</footer>
<a aria-label="post link to Gautier Dagan Dynamic Planning With a Llm 2023" class="entry-link" href="https://sino-huang.github.io/posts/gautier-dagan-dynamic-planning-with-a-llm-2023/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/jun-wang-conformal-temporal-logic-planning-using-llm-2023/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Jun Wang Conformal Temporal Logic Planning Using Llm 2023
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Conformal Temporal Logic Planning Using Llm 2023 Author: Jun Wang et. al. Publish Year: 19 Dec, 2023 Review Date: Sun, Jan 21, 2024 url: arXiv:2309.10092v2 Summary of paper Motivation Unlike previous methods that focus on low-level system configurations, this approach focuses on NL-based atomic propositions. now the LTL tasks are defined over NL-based atomic propositions Robots are required to perform high-level sub tasks specified in natural language. To formally define the overarching mission, they leverage LTL defined over atomic predicates modelling these NL-based sub-tasks. Contribution To address the challenge of ensuring the correctness of robot plans with respect to these LTL-encoded tasks, the authors propose HERACLEs, a hierarchical conformal natural language planner. HERACLEs employs automata theory to determine the next NL-specified sub-tasks for mission progress, employs Large Language Models to design robot plans to fulfill these sub-tasks, and uses conformal prediction to assess the probabilistic correctness of the plans, deciding whether external assistance is needed. The paper provides theoretical probabilistic guarantees for mission satisfaction and presents extensive comparative experiments on mobile manipulation tasks. Some key terms Limitation for previous work
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-21 00:34:56 +1100 AEDT">January 21, 2024</span> · 2 min · 357 words · Sukai Huang</footer>
<a aria-label="post link to Jun Wang Conformal Temporal Logic Planning Using Llm 2023" class="entry-link" href="https://sino-huang.github.io/posts/jun-wang-conformal-temporal-logic-planning-using-llm-2023/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/gerevini-plan-constraints-and-preferences-in-pddl3-2005/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Gerevini Plan Constraints and Preferences in Pddl3 2005
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Gerevini Plan Constraints and Preferences in PDDL3 Author: Alfonso Gerevini, Derek Long Publish Year: 2005 Review Date: Thu, Jan 11, 2024 url: http://www.cs.yale.edu/~dvm/papers/pddl-ipc5.pdf Summary of paper Motivation the notion of plan quality in automated planning is a practically very important issue. it is important to generate plans of good or optimal quality and we need to express the plan quality the proposed extended language allows us to express strong and soft constraints on plan trajectories i.e., constraints over possible actions in the plan and intermediate states reached by the plan as well as strong and soft problem goals. Some key terms some scenarios
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-11 19:54:29 +1100 AEDT">January 11, 2024</span> · 1 min · 122 words · Sukai Huang</footer>
<a aria-label="post link to Gerevini Plan Constraints and Preferences in Pddl3 2005" class="entry-link" href="https://sino-huang.github.io/posts/gerevini-plan-constraints-and-preferences-in-pddl3-2005/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/nir-lipo-planning-with-perspectives-using-functional-strips-2022/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Nir Lipo Planning With Perspectives Using Functional Strips 2022
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Planning With Perspectives – Using Decomposing Epistemic Planning using Functional STRIPS Author: Guang Hu, Nir Lipovetzky Publish Year: 2022 Review Date: Thu, Jan 11, 2024 url: https://nirlipo.github.io/publication/hu-2022-planning/ Summary of paper Motivation we present a novel approach to epistemic planning called planning with perspectives (PWP) that is both more expressive and computationally more efficient than existing state of the art epistemic planning tools. Contribution in this paper, we decompose epistemic planning by delegating reasoning about epistemic formulae to an external solver, i.e., Functional STRIPS F-STRIPS supports the user of external, black-box functions within action models. Building on recent work that demonstrates the relationship between what an agent ‘sees’ and what it knows, we define the perspective of each agent using an external function, and build a solver for epistemic logic around this. Some key terms external functions (black-box)
...</p>
</div>
<footer class="entry-footer"><span title="2024-01-11 19:41:55 +1100 AEDT">January 11, 2024</span> · 2 min · 267 words · Sukai Huang</footer>
<a aria-label="post link to Nir Lipo Planning With Perspectives Using Functional Strips 2022" class="entry-link" href="https://sino-huang.github.io/posts/nir-lipo-planning-with-perspectives-using-functional-strips-2022/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/alex_coulter-theory-alignment-via-a-classical-encoding-of-regular-bismulation-2022/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Alex_coulter Theory Alignment via a Classical Encoding of Regular Bismulation 2022
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Theory Alignment via a Classical Encoding of Regular Bismulation 2022 Author: Alex Coulter et. al. Publish Year: KEPS 2022 Review Date: Wed, Nov 29, 2023 url: https://icaps22.icaps-conference.org/workshops/KEPS/KEPS-22_paper_7781.pdf Summary of paper Motivation the main question we seek to answer is how we can test if two models align (where the fluents and action implementations may differ), and if not, where that misalignment occurs. Contribution the work is built on a foundation of regular bisimulation found that the proposed alignment was not only viable, with many submissions having “solutions” to the merged model showing where a modelling error occurs, but several cases demonstrated errors with the submitted domains that were subtle and detected only by this added approach. Some key terms Bisimulation
...</p>
</div>
<footer class="entry-footer"><span title="2023-11-29 17:24:08 +1100 AEDT">November 29, 2023</span> · 6 min · 1083 words · Sukai Huang</footer>
<a aria-label="post link to Alex_coulter Theory Alignment via a Classical Encoding of Regular Bismulation 2022" class="entry-link" href="https://sino-huang.github.io/posts/alex_coulter-theory-alignment-via-a-classical-encoding-of-regular-bismulation-2022/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/pascal-bercher-detecting-ai-planning-modelling-mistakes-potential-errors-and-benchmark-domains-2023/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Pascal Bercher Detecting Ai Planning Modelling Mistakes Potential Errors and Benchmark Domains 2023
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Detecting Ai Planning Modelling Mistakes Potential Errors and Benchmark Domains Author: Pascal Bercher et. al. Publish Year: 2023 Review Date: Mon, Nov 13, 2023 url: https://bercher.net/publications/2023/Sleath2023PossibleModelingErrors.pdf Summary of paper Contribution the author provided a compilation of potential modelling errors the author supply a public repository of 56 (flawed) benchmark domains conducted an evaluation of well-known AI planning tools for their ability to diagnose those errors, showing that not a single tool is able to spot all errors, with no tool being strictly stronger than another. Some key terms list of errors
...</p>
</div>
<footer class="entry-footer"><span title="2023-11-13 22:33:14 +1100 AEDT">November 13, 2023</span> · 2 min · 408 words · Sukai Huang</footer>
<a aria-label="post link to Pascal Bercher Detecting Ai Planning Modelling Mistakes Potential Errors and Benchmark Domains 2023" class="entry-link" href="https://sino-huang.github.io/posts/pascal-bercher-detecting-ai-planning-modelling-mistakes-potential-errors-and-benchmark-domains-2023/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/yecheng-jason-ma-eureka-human-level-reward-design-via-coding-large-language-models-2023/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Yecheng Jason Ma Eureka Human Level Reward Design via Coding Large Language Models 2023
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Eureka Human Level Reward Design via Coding Large Language Models 2023 Author: Yecheng Jason Ma et. al. Publish Year: 19 Oct 2023 Review Date: Fri, Oct 27, 2023 url: https://arxiv.org/pdf/2310.12931.pdf Summary of paper Motivation harnessing LLMs to learn complex low-level manipulation tasks, remains an open problem. we bridge this fundamental gap by using LLMs to produce rewards that can be used to acquire conplex skill via reinforcement learning. Contribution Eureka generate reward functions that outperform expert human-engineered rewards. the generality of Eureka also enables a new gradient-free in-context learning approach to reinforcement learning from human feedback (RLHF) Some key terms given detailed environmental code and natural language description about the task, the LLMs can generate reward function candidate sampling. As many real-world RL tasks admit sparse rewards that are difficult for learning, reward shaping that provides incremental learning signals is necessary in practice reward design problem
...</p>
</div>
<footer class="entry-footer"><span title="2023-10-27 16:44:22 +1100 AEDT">October 27, 2023</span> · 6 min · 1163 words · Sukai Huang</footer>
<a aria-label="post link to Yecheng Jason Ma Eureka Human Level Reward Design via Coding Large Language Models 2023" class="entry-link" href="https://sino-huang.github.io/posts/yecheng-jason-ma-eureka-human-level-reward-design-via-coding-large-language-models-2023/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/mark-chen-evaluating-large-language-models-trained-on-code-2021/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Mark Chen Evaluating Large Language Models Trained on Code 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Evaluating Large Language Models Trained on Code Author: Mark Chen et. al. OPENAI Publish Year: 14 Jul 2021 Review Date: Mon, Oct 16, 2023 url: https://arxiv.org/pdf/2107.03374.pdf Summary of paper Motivation it is the research paper behind Github Copilot tech more recently, language models have also fueled progress towards the longstanding challenge of program synthesis. Contribution we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. limitation difficulty with docstrings describing long chain of operations and with binding operations to variables. Some key terms HumanEval
...</p>
</div>
<footer class="entry-footer"><span title="2023-10-16 07:24:26 +1100 AEDT">October 16, 2023</span> · 2 min · 298 words · Sukai Huang</footer>
<a aria-label="post link to Mark Chen Evaluating Large Language Models Trained on Code 2021" class="entry-link" href="https://sino-huang.github.io/posts/mark-chen-evaluating-large-language-models-trained-on-code-2021/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/baptiste-roziere-code-llama-open-foundation-model-for-code-2023/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Baptiste Roziere Code Llama Open Foundation Model for Code 2023
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Code Llama Open Foundation Model for Code Author: Baptiste Roziere et. al. META AI Publish Year: 2023 Review Date: Mon, Oct 16, 2023 url: https://scontent.fmel13-1.fna.fbcdn.net/v/t39.2365-6/369856151_1754812304950972_1159666448927483931_n.pdf?_nc_cat=107&amp;ccb=1-7&amp;_nc_sid=3c67a6&amp;_nc_ohc=Hcg6QsYJx1wAX_okEZO&amp;_nc_ht=scontent.fmel13-1.fna&amp;oh=00_AfAYtfHJfYeomAQWiMUTRo96iP8d4sZrlIfD_KAeYlYaDQ&amp;oe=6531E8CF Summary of paper Motivation CODE Llama, support for large input contexts, and zero-shot instruction following ability for programming tasks. Contribution CODE llama reaches SOTA performance among open models on several code benchmarks Some key terms By training on domain-specific datasets, LLM have proved effective more broadly on applications that require advanced natural language understanding.
...</p>
</div>
<footer class="entry-footer"><span title="2023-10-16 02:58:20 +1100 AEDT">October 16, 2023</span> · 2 min · 284 words · Sukai Huang</footer>
<a aria-label="post link to Baptiste Roziere Code Llama Open Foundation Model for Code 2023" class="entry-link" href="https://sino-huang.github.io/posts/baptiste-roziere-code-llama-open-foundation-model-for-code-2023/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/haotian-liu-improved-baselines-with-visual-instruction-tuning-2023/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Haotian Liu Improved Baselines With Visual Instruction Tuning 2023
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Improved Baselines With Visual Instruction Tuning Author: Haotian Liu et. al. Publish Year: Oct 5 2023 Review Date: Sun, Oct 8, 2023 url: https://arxiv.org/pdf/2310.03744.pdf Summary of paper Motivation we show that the fully-connected vision-language cross-modal connector in LLaVA is surprisingly powerful and data-efficient. Contribution with simple modifications to LLaVA, namely, using CLIP-ViT with an MLP projection and adding academic-task-oriented VQA data with simple response formatting prompts, they establish stronger baseline. Some key terms Improvement one: MLP cross modal connector
...</p>
</div>
<footer class="entry-footer"><span title="2023-10-08 10:37:37 +1100 AEDT">October 8, 2023</span> · 2 min · 240 words · Sukai Huang</footer>
<a aria-label="post link to Haotian Liu Improved Baselines With Visual Instruction Tuning 2023" class="entry-link" href="https://sino-huang.github.io/posts/haotian-liu-improved-baselines-with-visual-instruction-tuning-2023/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/christabel-wayllace-goal-recognition-design-with-stochastic-agent-action-outcomes-2016/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Christabel Wayllace Goal Recognition Design With Stochastic Agent Action Outcomes 2016
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Christabel Wayllace Goal Recognition Design With Stochastic Agent Action Outcomes 2016 Author: Christable Wayllace et. al. Publish Year: IJCAI 2016 Review Date: Fri, Oct 6, 2023 url: https://www.ijcai.org/Proceedings/16/Papers/464.pdf Summary of paper Motivation in this paper, they generalize the Goal Recognition Design (GRD) problem to Stochastic GRD (S-GRD) problems, which handle stochastic action outcomes. Some key terms Plan and goal recognition problem
it aims to identify the actual plan or goal of an agent given its behaviour. Goal Recognition Design
...</p>
</div>
<footer class="entry-footer"><span title="2023-10-06 18:16:28 +1100 AEDT">October 6, 2023</span> · 1 min · 191 words · Sukai Huang</footer>
<a aria-label="post link to Christabel Wayllace Goal Recognition Design With Stochastic Agent Action Outcomes 2016" class="entry-link" href="https://sino-huang.github.io/posts/christabel-wayllace-goal-recognition-design-with-stochastic-agent-action-outcomes-2016/"></a>
</article>
<article class="post-entry">
<figure class="entry-cover"><img alt="" loading="lazy" src="https://sino-huang.github.io/posts/alba-gragera-pddl-domain-repair-fixing-domains-with-incomplete-action-effects-2023/image-assets/cover.png"/>
</figure>
<header class="entry-header">
<h2 class="entry-hint-parent">Alba Gragera Pddl Domain Repair Fixing Domains With Incomplete Action Effects 2023
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: PDDL Domain Repair Fixing Domains With Incomplete Action Effects Author: Alba Gragera et. al. Publish Year: ICAPS 2023 Review Date: Wed, Sep 20, 2023 url: https://icaps23.icaps-conference.org/demos/papers/2791_paper.pdf Summary of paper Contribution in this paper, they present a tool to repair planning models where the effects of some actions are incomplete. The received input is compiled to a new extended planning task, in which actions are permitted to insert possible missing effects. The solution is a plan that achieves the goals of the original problem while also alerting users of the modification made. ...</p>
</div>
<footer class="entry-footer"><span title="2023-09-20 23:17:51 +1000 AEST">September 20, 2023</span> · 1 min · 153 words · Sukai Huang</footer>
<a aria-label="post link to Alba Gragera Pddl Domain Repair Fixing Domains With Incomplete Action Effects 2023" class="entry-link" href="https://sino-huang.github.io/posts/alba-gragera-pddl-domain-repair-fixing-domains-with-incomplete-action-effects-2023/"></a>
</article>
<footer class="page-footer">
<ul class="post-tags">
</ul>
<nav class="pagination">
<a class="prev" href="https://sino-huang.github.io/posts/">
      « Prev 1/9
    </a>
<a class="next" href="https://sino-huang.github.io/posts/page/3/">Next 3/9 »
    </a>
</nav>
</footer>
</main>
<footer class="footer">
<span>© 2024 <a href="https://sino-huang.github.io/">Sukai Huang</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &amp;
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
</span>
</footer>
<a accesskey="g" aria-label="go to top" class="top-link" href="#top" id="top-link" title="Go to Top (Alt + G)">
<svg fill="currentColor" viewbox="0 0 12 6" xmlns="http://www.w3.org/2000/svg">
<path d="M12 6H0l6-6z"></path>
</svg>
</a>
<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>
</html>
