<!DOCTYPE html>
<html dir="auto" lang="en">
<head><meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<meta content="index, follow" name="robots"/>
<title>Posts | Sukai Huang</title>
<meta content="" name="keywords"/>
<meta content="Posts - Sukai Huang" name="description"/>
<meta content="Sukai Huang" name="author"/>
<link href="https://sino-huang.github.io/posts/" rel="canonical"/>
<meta content="IFgzhtDTVCjONQMwQsBfuf0ZyHdzUR5WFYzbWsf2Gf8" name="google-site-verification"/>
<link as="style" crossorigin="anonymous" href="/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css" integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet"/>
<link href="https://sino-huang.github.io/favicon.ico" rel="icon"/>
<link href="https://sino-huang.github.io/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="https://sino-huang.github.io/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="https://sino-huang.github.io/apple-touch-icon.png" rel="apple-touch-icon"/>
<link href="https://sino-huang.github.io/safari-pinned-tab.svg" rel="mask-icon"/>
<meta content="#2e2e33" name="theme-color"/>
<meta content="#2e2e33" name="msapplication-TileColor"/>
<link href="https://sino-huang.github.io/posts/index.xml" rel="alternate" type="application/rss+xml"/>
<link href="https://sino-huang.github.io/posts/" hreflang="en" rel="alternate"/>
<noscript>
<style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
<style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-TTFTV1EWH5"></script>
<script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-TTFTV1EWH5');
        }
      </script><meta content="https://sino-huang.github.io/posts/" property="og:url"/>
<meta content="Sukai Huang" property="og:site_name"/>
<meta content="Posts" property="og:title"/>
<meta content="Sukai's academic blog - storing weekly reports and research paper reviews" property="og:description"/>
<meta content="en" property="og:locale"/>
<meta content="website" property="og:type"/>
<meta content="https://sino-huang.github.io/cute_avatar.jpg" property="og:image"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="https://sino-huang.github.io/cute_avatar.jpg" name="twitter:image"/>
<meta content="Posts" name="twitter:title"/>
<meta content="Sukai's academic blog - storing weekly reports and research paper reviews" name="twitter:description"/>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://sino-huang.github.io/posts/"
    }
  ]
}
</script>
</head>
<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<header class="header">
<nav class="nav">
<div class="logo">
<a accesskey="h" href="https://sino-huang.github.io/" title="Sukai Huang (Alt + H)">Sukai Huang</a>
<div class="logo-switches">
<button accesskey="t" id="theme-toggle" title="(Alt + T)">
<svg fill="none" height="18" id="moon" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
</svg>
<svg fill="none" height="18" id="sun" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<circle cx="12" cy="12" r="5"></circle>
<line x1="12" x2="12" y1="1" y2="3"></line>
<line x1="12" x2="12" y1="21" y2="23"></line>
<line x1="4.22" x2="5.64" y1="4.22" y2="5.64"></line>
<line x1="18.36" x2="19.78" y1="18.36" y2="19.78"></line>
<line x1="1" x2="3" y1="12" y2="12"></line>
<line x1="21" x2="23" y1="12" y2="12"></line>
<line x1="4.22" x2="5.64" y1="19.78" y2="18.36"></line>
<line x1="18.36" x2="19.78" y1="5.64" y2="4.22"></line>
</svg>
</button>
</div>
</div>
<ul id="menu">
<li>
<a href="https://sino-huang.github.io/biography/" title="Biography">
<span>Biography</span>
</a>
</li>
<li>
<a href="https://sino-huang.github.io/archives" title="Archive">
<span>Archive</span>
</a>
</li>
<li>
<a href="https://sino-huang.github.io/tags/" title="Tags">
<span>Tags</span>
</a>
</li>
<li>
<a href="https://sino-huang.github.io/categories/" title="Categories">
<span>Categories</span>
</a>
</li>
<li>
<a accesskey="/" href="https://sino-huang.github.io/search/" title="Search (Alt + /)">
<span>Search</span>
</a>
</li>
</ul>
</nav>
</header>
<main class="main">
<header class="page-header"><div class="breadcrumbs"><a href="https://sino-huang.github.io/">Home</a></div>
<h1>
    Posts
    <a aria-label="RSS" href="/posts/index.xml" title="RSS">
<svg fill="none" height="23" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
<path d="M4 11a9 9 0 0 1 9 9"></path>
<path d="M4 4a16 16 0 0 1 16 16"></path>
<circle cx="5" cy="19" r="1"></circle>
</svg>
</a>
</h1>
</header>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Joseph_kim Collaborative Planning With Encoding of High Level Strategies 2017
    </h2>
</header>
<div class="entry-content">
<p>please modify the following
[TOC]
Title: Collaborative Planning with Encoding of Users’ High-level Strategies Author: Joseph Kim et. al. Publish Year: 2017 Review Date: Mar 2022 Summary of paper Motivation Automatic planning is computationally expensive. Greedy search heuristics often yield low-quality plans that can result in wasted resources; also, even in the event that an adequate plan is generated, users may have difficulty interpreting the reason why the plan performs well and trusting it.
...</p>
</div>
<footer class="entry-footer"><span title="2022-03-04 12:12:27 +1100 AEDT">March 4, 2022</span> · 2 min · Sukai Huang</footer>
<a aria-label="post link to Joseph_kim Collaborative Planning With Encoding of High Level Strategies 2017" class="entry-link" href="https://sino-huang.github.io/posts/joseph_kim-collaborative-planning-with-encoding-of-high-level-strategies-2017/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Mikayel_samvelyan Minihack the Planet a Sandbox for Open Ended Rl Research 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: MiniHack the Planet: A Sandbox for Open-Ended Reinforcement Learning Research Author: Mikayel Samvelyan et. al. Publish Year: Nov 2021 Review Date: Mar 2022 Summary of paper They presented MiniHack, an easy-to-use framework for creating rich and varied RL environments, as well as a suite of tasks developed using this framework. Built upon NLE and the des-file format, MiniHack enables the use of rich entities and dynamics from the game of NetHack to create a large variety of RL environments for targeted experimentation, while also allowing painless scaling-up of the difficulty of existing environments. MiniHack’s environments are procedurally generated by default, ensuring the evaluation of systematic generalization of RL agents.
...</p>
</div>
<footer class="entry-footer"><span title="2022-03-04 12:11:55 +1100 AEDT">March 4, 2022</span> · 3 min · Sukai Huang</footer>
<a aria-label="post link to Mikayel_samvelyan Minihack the Planet a Sandbox for Open Ended Rl Research 2021" class="entry-link" href="https://sino-huang.github.io/posts/mikayel_samvelyan-minihack-the-planet-a-sandbox-for-open-ended-rl-research-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Richard_shin Constrained Language Models Yield Few Shot Semantic Parsers 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Constrained Language models yield few-shot semantic parsers Author: Richard Shin et. al. Publish Year: Nov 2021 Review Date: Mar 2022 Summary of paper Motivation The author wanted to explore the use of large pretrained language models as few-shot semantic parsers
However, language models are trained to generate natural language. To bridge the gap, they used language models to paraphrase inputs into a controlled sublanguage resembling English that can be automatically mapped to a target meaning representation. (using synchronous context-free grammar SCFG)
...</p>
</div>
<footer class="entry-footer"><span title="2022-03-02 00:19:18 +1100 AEDT">March 2, 2022</span> · 1 min · Sukai Huang</footer>
<a aria-label="post link to Richard_shin Constrained Language Models Yield Few Shot Semantic Parsers 2021" class="entry-link" href="https://sino-huang.github.io/posts/richard_shin-constrained-language-models-yield-few-shot-semantic-parsers-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Heinrich_kuttler the Nethack Learning Environment 2020
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: The NetHack Learning Environment Author: Heinrich Kuttler et. al. Publish Year: Dec 2020 Review Date: Mar 2022 Summary of paper The NetHack Learning Environment (NLE), a scalable, procedurally generated, stochastic, rich, and challenging environment for RL research based on the popular single-player terminal-based roguelike game, NetHack.
NetHack is sufficiently complex to drive long-term research on problems such as exploration, planning, skill acquisition, and language-conditioned RL, while dramatically reducing the computational resources required to gather a large amount of experience.
...</p>
</div>
<footer class="entry-footer"><span title="2022-03-02 00:18:35 +1100 AEDT">March 2, 2022</span> · 3 min · Sukai Huang</footer>
<a aria-label="post link to Heinrich_kuttler the Nethack Learning Environment 2020" class="entry-link" href="https://sino-huang.github.io/posts/heinrich_kuttler-the-nethack-learning-environment-2020/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Pashootan_vaezipoor Ltl2action Generalising Ltl Instructions for Multi Task Rl 2021
    </h2>
</header>
<div class="entry-content">
<p>please modify the following
[TOC]
Title: LTL2Action: Generalizing LTL Instructions for Multi-Task RL Author: Pashootan Vaezipoor et. al. Publish Year: 2021 Review Date: March 2022 Summary of paper Motivation they addressed the problem of teaching a deep reinforcement learning agent to follow instructions in multi-task environments. Instructions are expressed in a well-known formal language – linear temporal logic (LTL)
Limitation of the vanilla MDP
temporal constraints cannot be expressed as rewards in MDP setting and thus modular policy and other stuffs are not able to obtain maximum rewards.
...</p>
</div>
<footer class="entry-footer"><span title="2022-03-01 20:53:10 +1100 AEDT">March 1, 2022</span> · 3 min · Sukai Huang</footer>
<a aria-label="post link to Pashootan_vaezipoor Ltl2action Generalising Ltl Instructions for Multi Task Rl 2021" class="entry-link" href="https://sino-huang.github.io/posts/pashootan_vaezipoor-ltl2action-generalising-ltl-instructions-for-multi-task-rl-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Roma_patel Learning to Ground Language Temporal Logical Form 2019
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Learning to Ground Language to Temporal Logical Form Author: Roma Patel et. al. Publish Year: 2019 Review Date: Feb 2022 Summary of paper Motivation natural language commands often exhibits sequential (temporal) constraints e.g., “go through the kitchen and then into the living room”.
But this constraints cannot be expressed in the reward of Markov Decision Process setting. (see this paper)
Therefore, they proposed to ground language to Linear Temporal logic (LTL) and after that continue to map from LTL expressions to action sequences.
...</p>
</div>
<footer class="entry-footer"><span title="2022-02-28 21:40:53 +1100 AEDT">February 28, 2022</span> · 2 min · Sukai Huang</footer>
<a aria-label="post link to Roma_patel Learning to Ground Language Temporal Logical Form 2019" class="entry-link" href="https://sino-huang.github.io/posts/roma_patel-learning-to-ground-language-temporal-logical-form-2019/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Thang_m_pham Out of Order How Important Is the Sequential Order of Words in a Sentence in Natural Language Understanding Tasks 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Out of Order: How Important Is The Sequential Order of Words in a Sentence in Natural Language Understanding Tasks? Author: Thang M. Pham Publish Year: Jul 2021 Review Date: Feb 2022 Summary of paper The author found out that BERT-based models trained on GLUE have low sensitivity to word orders.
The research questions are the following
Do BERT-based models trained on GLUE care about the order of words in a sentence? ANS: NO, except one task named CoLA, which is to detecting grammatically incorrect sentences. Surprisingly, for the rest of the 5 out of 6 binary-classification tasks (i.e. except CoLA), between75% and 90% of the originally correct predictions remain constant after 1-grams are randomly re-ordered Are SOTA BERT-based models using word order information when solving NLU tasks? If not, what cues do they rely on? ANS: they heavily rely on the word itself rather than the ordering. The results showed that if the top - 1 most important word measured by LIME has a positive meaning, then there is 100% probability that the sentence’s label is “positive” Results
...</p>
</div>
<footer class="entry-footer"><span title="2022-02-28 18:58:52 +1100 AEDT">February 28, 2022</span> · 2 min · Sukai Huang</footer>
<a aria-label="post link to Thang_m_pham Out of Order How Important Is the Sequential Order of Words in a Sentence in Natural Language Understanding Tasks 2021" class="entry-link" href="https://sino-huang.github.io/posts/thang_m_pham-out-of-order-how-important-is-the-sequential-order-of-words-in-a-sentence-in-natural-language-understanding-tasks-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Anton_belyy Guided K Best Selection for Semantic Parsing Annotation 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Guided K-best Selection for Semantic Parsing Annotation Author: Anton Belyy et. al. Publish Year: 2021 Review Date: Feb 2022 Summary of paper Motivation They wanted to tackle the challenge of efficient data collection (data annotation) for the conversational semantic parsing task.
In the presence of little available training data, they proposed human-in-the-loop interfaces for guided K-best selection, using a prototype model trained on limited data.
Result Their user studies showed that the keyword searching function combined with a keyword suggestion method strikes the balance between annotation accuracy and speed
...</p>
</div>
<footer class="entry-footer"><span title="2022-02-23 19:42:39 +1100 AEDT">February 23, 2022</span> · 3 min · Sukai Huang</footer>
<a aria-label="post link to Anton_belyy Guided K Best Selection for Semantic Parsing Annotation 2021" class="entry-link" href="https://sino-huang.github.io/posts/anton_belyy-guided-k-best-selection-for-semantic-parsing-annotation-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">S_teufel Argumentative Zoning 2000
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Argumentative Zoning Author: Simone Teufel Publish Year: 2000 Review Date: Feb 2022 https://www.cl.cam.ac.uk/~sht25/az.html
Summary Abstract We present a new type of analysis for scientific text which we call Argumentative Zoning.
We demonstrate that this type of text analysis can be used for generating user-tailored and task-tailored summaries and for performing more informative citation analyses.
We also demonstrate that our type of analysis can be applied to unrestricted text, both automatically and by humans. The corpus we use for the analysis (80 conference papers in computational linguistics) is a difficult test bed; it shows great variation with respect to subdomain, writing style, register and linguistic expression. We present reliability studies which we performed on this corpus and for which we use two unrelated trained annotators.
...</p>
</div>
<footer class="entry-footer"><span title="2022-02-16 14:40:57 +1100 AEDT">February 16, 2022</span> · 2 min · Sukai Huang</footer>
<a aria-label="post link to S_teufel Argumentative Zoning 2000" class="entry-link" href="https://sino-huang.github.io/posts/s_teufel-argumentative-zoning-2000/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Jacob_andreas Compositionality as Lexical Symmetry 2022
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Compositionality as Lexical Symmetry Author: Ekin Akyurek; Jacob Andreas Publish Year: Jan 2022 Review Date: Feb 2022 Summary of paper Motivation Standard deep network models lack the inductive bias needed to generalize compositionally in tasks like semantic parsing, translation, and question answering.
So, a large body of work in NLP seeks to overcome this limitation with new model architectures that enforce a compositional process of sentence interpretation.
Goal
...</p>
</div>
<footer class="entry-footer"><span title="2022-02-08 14:20:19 +1100 AEDT">February 8, 2022</span> · 2 min · Sukai Huang</footer>
<a aria-label="post link to Jacob_andreas Compositionality as Lexical Symmetry 2022" class="entry-link" href="https://sino-huang.github.io/posts/jacob_andreas-compositionality-as-lexical-symmetry-2022/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Tao_lei When Attention Meets Fast Recurrence Training Language Models With Reduced Compute 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: When Attention Meets Fast Recurrence: Training Language Models with Reduce Compute Author: Tao Lei Publish Year: Sep 2021 Review Date: Jan 2022 Summary of paper As the author mentioned, the inspiration of SRU++ comes from two lines of research:
paralleization / speed problem of Original RNN leveraging recurrence in conjunction with self-attention Structure of SRU++
New discovery :little attention is needed given recurrence.
Similar to the observation of Merity (2019), they found using a couple of attention layers sufficient to obtain SOTA results.
...</p>
</div>
<footer class="entry-footer"><span title="2022-01-14 00:26:37 +1100 AEDT">January 14, 2022</span> · 1 min · Sukai Huang</footer>
<a aria-label="post link to Tao_lei When Attention Meets Fast Recurrence Training Language Models With Reduced Compute 2021" class="entry-link" href="https://sino-huang.github.io/posts/tao_lei-when-attention-meets-fast-recurrence-training-language-models-with-reduced-compute-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Alex_nichol Glide Towards Photorealistic Image Generation and Editing With Text Guided Diffusion Models 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models Author: Alex Nichol et. al. Publish Year: Dec 2021 Review Date: Jan 2022 Summary of paper In author’s previous work, the diffusion model can achieve photorealism in the class-conditional setting by augmenting with classifier guidance, a technique which allows diffusion models to condition on a classifier’s labels.
The classifier is first trained on noised images, and during the diffusion sampling process, gradients from the classifier are used to guide the output sample towards the label. classifier details
...</p>
</div>
<footer class="entry-footer"><span title="2022-01-12 16:54:01 +1100 AEDT">January 12, 2022</span> · 2 min · Sukai Huang</footer>
<a aria-label="post link to Alex_nichol Glide Towards Photorealistic Image Generation and Editing With Text Guided Diffusion Models 2021" class="entry-link" href="https://sino-huang.github.io/posts/alex_nichol-glide-towards-photorealistic-image-generation-and-editing-with-text-guided-diffusion-models-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Junyang_lin M6 a Chinese Multimodal Pretrainer 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: M6: A Chinese Multimodal Pretrainer Author: Junyang Lin et. al. Publish Year: May 2021 Review Date: Jan 2022 Summary of paper This paper re-emphasises that
large model trained on big data have extremely large capacity and it can outperform the SOTA in downstream tasks especially in the zero-shot setting. So, the author trained a big multi-modal model
Also, they proposed a innovative way to tackle downstream tasks.
they use masks to block cross attention between tokens so as to fit different types of downstream task Key idea: mask tokens during cross attention so as to solve certain tasks Overview
...</p>
</div>
<footer class="entry-footer"><span title="2022-01-12 13:38:14 +1100 AEDT">January 12, 2022</span> · 1 min · Sukai Huang</footer>
<a aria-label="post link to Junyang_lin M6 a Chinese Multimodal Pretrainer 2021" class="entry-link" href="https://sino-huang.github.io/posts/junyang_lin-m6-a-chinese-multimodal-pretrainer-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Tianshi_cao Babyai Plus Plus Towards Grounded Language Learning Beyond Memorization 2020
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: BABYAI++: Towards Grounded-Language Learning Beyond Memorization Author: Tianshi Cao et. al. Publish Year: 2020 ICLR Review Date: Jan 2022 Summary of paper The paper introduced a new RL environment BabyAI++ that can investigate whether RL agents can extract knowledge from descriptive text and eventually increase generalisation performance.
BabyAI++ environment example
the descriptive text describe the feature of the object. notice that the feature of object can easily change as we change the descriptive text. Model
...</p>
</div>
<footer class="entry-footer"><span title="2022-01-03 22:38:40 +1100 AEDT">January 3, 2022</span> · 1 min · Sukai Huang</footer>
<a aria-label="post link to Tianshi_cao Babyai Plus Plus Towards Grounded Language Learning Beyond Memorization 2020" class="entry-link" href="https://sino-huang.github.io/posts/tianshi_cao-babyai-plus-plus-towards-grounded-language-learning-beyond-memorization-2020/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Federico_bianchi Language in a Search Box Grounding Language Learning in Real World Human Machine Interaction 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Language in a (Search) Box: Grounding Language Learning in Real-World Human-Machine Interaction Author: Federico Bianchi Publish Year: 2021 Review Date: Jan 2022 Summary of paper the author investigated grounded language learning through the natural interaction between users and the shopping website search engine.
How they do it
convert the shopping object dataset into a Latent Grounded Domain
related products end up closer in the embedding space train the mapping model (mapping from text query to a portion of product space) based on the user click behaviour (In the training dataset, the users queries about “Nike” and the they would click relevant Nike Product)
...</p>
</div>
<footer class="entry-footer"><span title="2022-01-03 16:51:39 +1100 AEDT">January 3, 2022</span> · 1 min · Sukai Huang</footer>
<a aria-label="post link to Federico_bianchi Language in a Search Box Grounding Language Learning in Real World Human Machine Interaction 2021" class="entry-link" href="https://sino-huang.github.io/posts/federico_bianchi-language-in-a-search-box-grounding-language-learning-in-real-world-human-machine-interaction-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Lili_chen Decision Transformer Reinforcement Learning via Sequence Modeling 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Decision Transformer: Reinforcement Learning via Sequence Modeling Author: Lili Chen et. al. Publish Year: Jun 2021 Review Date: Dec 2021 Summary of paper The Architecture of Decision Transformer
Inputs are reward, observation and action
Outputs are action, in training time, the future action will be masked out.
I believe this model is able to generate a very good long sequence of actions due to transformer architecture.
But somehow this is not RL anymore because the transformer is not trained by reward signal …
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-24 23:29:49 +1100 AEDT">December 24, 2021</span> · 2 min · Sukai Huang</footer>
<a aria-label="post link to Lili_chen Decision Transformer Reinforcement Learning via Sequence Modeling 2021" class="entry-link" href="https://sino-huang.github.io/posts/lili_chen-decision-transformer-reinforcement-learning-via-sequence-modeling-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Jiayuan_mao Grammar Based Grounded Lexicon Learning 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Grammar-Based Grounded Lexicon Learning Author: Jiayuan Mao Publish Year: 2021 NeurIPS Review Date: Dec 2021 Summary of paper The paper extend the previous work “Neuro-Symbolic Concept Learner” by parsing the natural language questions using symbolic manner.
The core semantic parsing technique is Combinatory Categorical Grammar with CKY algorithm to prune unlikely expressions.
The full picture looks like this
The detailed algorithm process looks like this
How to derive concept embedding
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-22 17:22:15 +1100 AEDT">December 22, 2021</span> · 2 min · Sukai Huang</footer>
<a aria-label="post link to Jiayuan_mao Grammar Based Grounded Lexicon Learning 2021" class="entry-link" href="https://sino-huang.github.io/posts/jiayuan_mao-grammar-based-grounded-lexicon-learning-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Julia_kiseleva Interactive Grounded Language Understanding in a Collaborative Environment 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Interactive Grounded Language Understanding in a Collaborative Environment Author: Julia Kiseleva et. al. Publish Year: 2021 Review Date: Dec 2021 Summary of paper The primary goal of the competition is to approach the problem of how to build interactive agents that learn to solve a task while provided with grounded natural language instructions in a collaborative environment.
The split the problem into following concrete research questions, which correspond to separate tasks that can be used to study each component individually before joining all of them into one system
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-22 15:10:56 +1100 AEDT">December 22, 2021</span> · 2 min · Sukai Huang</footer>
<a aria-label="post link to Julia_kiseleva Interactive Grounded Language Understanding in a Collaborative Environment 2021" class="entry-link" href="https://sino-huang.github.io/posts/julia_kiseleva-interactive-grounded-language-understanding-in-a-collaborative-environment-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Dominik_drexler Expressing and Exploiting the Common Subgoal Structure of Classical Planning Domains Using Sketches 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Expressing and Exploiting the Common Subgoal Structure of Classical Planning Domains Using Sketches Author: Dominik Drexler et. al. Publish Year: 2021 Review Date: Dec 2021 Summary of paper Algorithms like SIW often fail when the goal is not easily serialisable or when some of the subproblems have a high width. In this work, the author address these limitations by using a simple but powerful language for expressing finer problem decompositions called policy sketches.
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-17 13:07:53 +1100 AEDT">December 17, 2021</span> · 3 min · Sukai Huang</footer>
<a aria-label="post link to Dominik_drexler Expressing and Exploiting the Common Subgoal Structure of Classical Planning Domains Using Sketches 2021" class="entry-link" href="https://sino-huang.github.io/posts/dominik_drexler-expressing-and-exploiting-the-common-subgoal-structure-of-classical-planning-domains-using-sketches-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Yiding_jiang Language as Abstraction for Hierarchical Deep Reinforcement Learning
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Language as an Abstraction for Hierarchical Deep Reinforcement Learning Author: Yiding Jiang et. al. Publish Year: 2019 NeurIPS Review Date: Dec 2021 Summary of paper Solving complex, temporally-extended tasks is a long-standing problem in RL.
Acquiring effective yet general abstractions for hierarchical RL is remarkably challenging.
Therefore, they propose to use language as the abstraction, as it provides unique compositional structure, enabling fast learning and combinatorial generalisation
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-15 19:49:28 +1100 AEDT">December 15, 2021</span> · 3 min · Sukai Huang</footer>
<a aria-label="post link to Yiding_jiang Language as Abstraction for Hierarchical Deep Reinforcement Learning" class="entry-link" href="https://sino-huang.github.io/posts/yiding_jiang-language-as-abstraction-for-hierarchical-deep-reinforcement-learning/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Hengyuan_hu Hierarchical Decision Making by Generating and Following Natural Language Instructions 2019
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Hierarchical Decision Making by Generating and Following Natural Language Instructions Author: Hengyuan Hu et. al. FAIR Publish Year: 2019 Review Date: Dec 2021 Summary of paper One line summary: they build a Architect Builder model to clone human behaviour for playing RTS game
Their task environment is very similar to IGLU competition setting, but their model is too task-specific
The author mentioned some properties about natural language instructions
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-15 13:11:05 +1100 AEDT">December 15, 2021</span> · 2 min · Sukai Huang</footer>
<a aria-label="post link to Hengyuan_hu Hierarchical Decision Making by Generating and Following Natural Language Instructions 2019" class="entry-link" href="https://sino-huang.github.io/posts/hengyuan_hu-hierarchical-decision-making-by-generating-and-following-natural-language-instructions-2019/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">David_ding Attention Over Learned Object Embeddings Enables Complex Visual Reasoning 2021
    </h2>
</header>
<div class="entry-content">
<p> Title: Attention Over Learned Object Embeddings Enables Complex Visual Reasoning Author: David Ding et. al. Publish Year: 2021 NeurIPS Review Date: Dec 2021 Background info for this paper:
Their paper propose a all-in-one transformer model that is able to answer CLEVRER counterfactual questions with higher accuracy (75.6% vs 46.5%) and less training data (- 40%)
They believe that their model relies on three key aspects:
self-attention soft-discretization self-supervised learning ...</p>
</div>
<footer class="entry-footer"><span title="2021-12-15 12:59:07 +1100 AEDT">December 15, 2021</span> · 3 min · Sukai Huang</footer>
<a aria-label="post link to David_ding Attention Over Learned Object Embeddings Enables Complex Visual Reasoning 2021" class="entry-link" href="https://sino-huang.github.io/posts/david_ding-attention-over-learned-object-embeddings-enables-complex-visual-reasoning-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Jacob_andreas Modular Multitask Reinforcement Learning With Policy Sketches 2017
    </h2>
</header>
<div class="entry-content">
<p> Title: Modular Multitask Reinforcement Learning with Policy Sketches Author: Jacob Andreas et. al. Publish Year: 2017 Review Date: Dec 2021 Background info for this paper:
Their paper describe a framework that is inspired by on options MDP, for which a reinforcement learning task is handled by several sub-MDP modules. (that is why they call it Modular RL)
They consider a multitask RL problem in a shared environment. (See the figure below). The IGLU Minecraft challenge as well as Angry Birds also belongs to this category.
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-13 17:23:12 +1100 AEDT">December 13, 2021</span> · 3 min · Sukai Huang</footer>
<a aria-label="post link to Jacob_andreas Modular Multitask Reinforcement Learning With Policy Sketches 2017" class="entry-link" href="https://sino-huang.github.io/posts/jacob_andreas-modular-multitask-reinforcement-learning-with-policy-sketches-2017/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">David_abel on the Expressivity of Markov Reward 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: On the Expressivity of Markov Reward Author: David Abel et. al. Publish Year: NuerIPS 2021 Review Date: 6 Dec 2021 Summary of paper This needs to be only 1-3 sentences, but it demonstrates that you understand the paper and, moreover, can summarize it more concisely than the author in his abstract.
The author found out that in the Markov Decision Process scenario, (i.e., we do not look at the history of the trajectory to provide rewards), some tasks cannot be realised perfectly by reward functions. i.e.,
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-05 12:02:23 +1100 AEDT">December 5, 2021</span> · 5 min · Sukai Huang</footer>
<a aria-label="post link to David_abel on the Expressivity of Markov Reward 2021" class="entry-link" href="https://sino-huang.github.io/posts/david_abel-on-the-expressivity-of-markov-reward-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Rishabh_agarwal Deep Reinforcement Learning at the Edge of the Stats Precipice 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Deep Reinforcement Learning at the Edge of the Statistical Precipice Author: Rishabh Agarwal et. al. Publish Year: NeurIPS 2021 Review Date: 3 Dec 2021 Summary of paper This needs to be only 1-3 sentences, but it demonstrates that you understand the paper and, moreover, can summarize it more concisely than the author in his abstract.
Most current published results on deep RL benchmarks uses point estimate of aggregate performance such as mean and median score across the task.
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-03 19:50:10 +1100 AEDT">December 3, 2021</span> · 3 min · Sukai Huang</footer>
<a aria-label="post link to Rishabh_agarwal Deep Reinforcement Learning at the Edge of the Stats Precipice 2021" class="entry-link" href="https://sino-huang.github.io/posts/rishabh_agarwal-deep-reinforcement-learning-at-the-edge-of-the-stats-precipice-2021/"></a>
</article>
<footer class="page-footer">
<ul class="post-tags">
</ul>
<nav class="pagination">
<a class="prev" href="https://sino-huang.github.io/posts/page/7/">
      « Prev 7/9
    </a>
<a class="next" href="https://sino-huang.github.io/posts/page/9/">Next 9/9 »
    </a>
</nav>
</footer>
</main>
<footer class="footer">
<span>© 2024 <a href="https://sino-huang.github.io/">Sukai Huang</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &amp;
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
</span>
</footer>
<a accesskey="g" aria-label="go to top" class="top-link" href="#top" id="top-link" title="Go to Top (Alt + G)">
<svg fill="currentColor" viewbox="0 0 12 6" xmlns="http://www.w3.org/2000/svg">
<path d="M12 6H0l6-6z"></path>
</svg>
</a>
<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>
</html>
