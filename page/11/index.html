<!DOCTYPE html>
<html dir="auto" lang="en">
<head>
<meta content="Hugo 0.139.2" name="generator"/><script data-no-instant="" defer="" src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload"></script><meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<meta content="index, follow" name="robots"/>
<title>Sukai Huang</title>
<meta content="Sukai's academic blog - storing weekly reports and research paper reviews" name="description"/>
<meta content="Sukai Huang" name="author"/>
<link href="http://localhost:1313/" rel="canonical"/>
<meta content="IFgzhtDTVCjONQMwQsBfuf0ZyHdzUR5WFYzbWsf2Gf8" name="google-site-verification"/>
<link as="style" crossorigin="anonymous" href="/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css" integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet"/>
<link href="http://localhost:1313/favicon.ico" rel="icon"/>
<link href="http://localhost:1313/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="http://localhost:1313/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="http://localhost:1313/apple-touch-icon.png" rel="apple-touch-icon"/>
<link href="http://localhost:1313/safari-pinned-tab.svg" rel="mask-icon"/>
<meta content="#2e2e33" name="theme-color"/>
<meta content="#2e2e33" name="msapplication-TileColor"/>
<link href="http://localhost:1313/index.xml" rel="alternate" type="application/rss+xml"/>
<link href="http://localhost:1313/index.json" rel="alternate" type="application/json"/>
<link href="http://localhost:1313/" hreflang="en" rel="alternate"/>
<noscript>
<style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
<style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-TTFTV1EWH5"></script>
<script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-TTFTV1EWH5');
        }
      </script><meta content="http://localhost:1313/" property="og:url"/>
<meta content="Sukai Huang" property="og:site_name"/>
<meta content="Sukai Huang" property="og:title"/>
<meta content="Sukai's academic blog - storing weekly reports and research paper reviews" property="og:description"/>
<meta content="en" property="og:locale"/>
<meta content="website" property="og:type"/>
<meta content="http://localhost:1313/cute_avatar.jpg" property="og:image"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="http://localhost:1313/cute_avatar.jpg" name="twitter:image"/>
<meta content="Sukai Huang" name="twitter:title"/>
<meta content="Sukai's academic blog - storing weekly reports and research paper reviews" name="twitter:description"/>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Organization",
  "name": "Sukai Huang",
  "url": "http://localhost:1313/",
  "description": "Sukai's academic blog - storing weekly reports and research paper reviews",
  "logo": "http://localhost:1313/favicon.ico",
  "sameAs": [
      "https://github.com/Sino-Huang", "mailto:sukaih@student.unimelb.edu.au", "https://au.linkedin.com/in/sukai-huang-683368169"
  ]
}
</script>
</head>
<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<header class="header">
<nav class="nav">
<div class="logo">
<a accesskey="h" href="http://localhost:1313/" title="Sukai Huang (Alt + H)">Sukai Huang</a>
<div class="logo-switches">
<button accesskey="t" id="theme-toggle" title="(Alt + T)">
<svg fill="none" height="18" id="moon" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
</svg>
<svg fill="none" height="18" id="sun" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<circle cx="12" cy="12" r="5"></circle>
<line x1="12" x2="12" y1="1" y2="3"></line>
<line x1="12" x2="12" y1="21" y2="23"></line>
<line x1="4.22" x2="5.64" y1="4.22" y2="5.64"></line>
<line x1="18.36" x2="19.78" y1="18.36" y2="19.78"></line>
<line x1="1" x2="3" y1="12" y2="12"></line>
<line x1="21" x2="23" y1="12" y2="12"></line>
<line x1="4.22" x2="5.64" y1="19.78" y2="18.36"></line>
<line x1="18.36" x2="19.78" y1="5.64" y2="4.22"></line>
</svg>
</button>
</div>
</div>
<ul id="menu">
<li>
<a href="http://localhost:1313/biography/" title="Biography">
<span>Biography</span>
</a>
</li>
<li>
<a href="http://localhost:1313/archives" title="Archive">
<span>Archive</span>
</a>
</li>
<li>
<a href="http://localhost:1313/tags/" title="Tags">
<span>Tags</span>
</a>
</li>
<li>
<a href="http://localhost:1313/categories/" title="Categories">
<span>Categories</span>
</a>
</li>
<li>
<a accesskey="/" href="http://localhost:1313/search/" title="Search (Alt + /)">
<span>Search</span>
</a>
</li>
</ul>
</nav>
</header>
<main class="main">
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Tianshi_cao Babyai Plus Plus Towards Grounded Language Learning Beyond Memorization 2020
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: BABYAI++: Towards Grounded-Language Learning Beyond Memorization Author: Tianshi Cao et. al. Publish Year: 2020 ICLR Review Date: Jan 2022 Summary of paper The paper introduced a new RL environment BabyAI++ that can investigate whether RL agents can extract knowledge from descriptive text and eventually increase generalisation performance.
BabyAI++ environment example
the descriptive text describe the feature of the object. notice that the feature of object can easily change as we change the descriptive text. Model
...</p>
</div>
<footer class="entry-footer"><span title="2022-01-03 22:38:40 +1100 AEDT">January 3, 2022</span> · 1 min · Sukai Huang</footer>
<a aria-label="post link to Tianshi_cao Babyai Plus Plus Towards Grounded Language Learning Beyond Memorization 2020" class="entry-link" href="http://localhost:1313/posts/tianshi_cao-babyai-plus-plus-towards-grounded-language-learning-beyond-memorization-2020/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Federico_bianchi Language in a Search Box Grounding Language Learning in Real World Human Machine Interaction 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Language in a (Search) Box: Grounding Language Learning in Real-World Human-Machine Interaction Author: Federico Bianchi Publish Year: 2021 Review Date: Jan 2022 Summary of paper the author investigated grounded language learning through the natural interaction between users and the shopping website search engine.
How they do it
convert the shopping object dataset into a Latent Grounded Domain
related products end up closer in the embedding space train the mapping model (mapping from text query to a portion of product space) based on the user click behaviour (In the training dataset, the users queries about “Nike” and the they would click relevant Nike Product)
...</p>
</div>
<footer class="entry-footer"><span title="2022-01-03 16:51:39 +1100 AEDT">January 3, 2022</span> · 1 min · Sukai Huang</footer>
<a aria-label="post link to Federico_bianchi Language in a Search Box Grounding Language Learning in Real World Human Machine Interaction 2021" class="entry-link" href="http://localhost:1313/posts/federico_bianchi-language-in-a-search-box-grounding-language-learning-in-real-world-human-machine-interaction-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Lili_chen Decision Transformer Reinforcement Learning via Sequence Modeling 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Decision Transformer: Reinforcement Learning via Sequence Modeling Author: Lili Chen et. al. Publish Year: Jun 2021 Review Date: Dec 2021 Summary of paper The Architecture of Decision Transformer
Inputs are reward, observation and action
Outputs are action, in training time, the future action will be masked out.
I believe this model is able to generate a very good long sequence of actions due to transformer architecture.
But somehow this is not RL anymore because the transformer is not trained by reward signal …
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-24 23:29:49 +1100 AEDT">December 24, 2021</span> · 2 min · Sukai Huang</footer>
<a aria-label="post link to Lili_chen Decision Transformer Reinforcement Learning via Sequence Modeling 2021" class="entry-link" href="http://localhost:1313/posts/lili_chen-decision-transformer-reinforcement-learning-via-sequence-modeling-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Jiayuan_mao Grammar Based Grounded Lexicon Learning 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Grammar-Based Grounded Lexicon Learning Author: Jiayuan Mao Publish Year: 2021 NeurIPS Review Date: Dec 2021 Summary of paper The paper extend the previous work “Neuro-Symbolic Concept Learner” by parsing the natural language questions using symbolic manner.
The core semantic parsing technique is Combinatory Categorical Grammar with CKY algorithm to prune unlikely expressions.
The full picture looks like this
The detailed algorithm process looks like this
How to derive concept embedding
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-22 17:22:15 +1100 AEDT">December 22, 2021</span> · 2 min · Sukai Huang</footer>
<a aria-label="post link to Jiayuan_mao Grammar Based Grounded Lexicon Learning 2021" class="entry-link" href="http://localhost:1313/posts/jiayuan_mao-grammar-based-grounded-lexicon-learning-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Julia_kiseleva Interactive Grounded Language Understanding in a Collaborative Environment 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Interactive Grounded Language Understanding in a Collaborative Environment Author: Julia Kiseleva et. al. Publish Year: 2021 Review Date: Dec 2021 Summary of paper The primary goal of the competition is to approach the problem of how to build interactive agents that learn to solve a task while provided with grounded natural language instructions in a collaborative environment.
The split the problem into following concrete research questions, which correspond to separate tasks that can be used to study each component individually before joining all of them into one system
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-22 15:10:56 +1100 AEDT">December 22, 2021</span> · 2 min · Sukai Huang</footer>
<a aria-label="post link to Julia_kiseleva Interactive Grounded Language Understanding in a Collaborative Environment 2021" class="entry-link" href="http://localhost:1313/posts/julia_kiseleva-interactive-grounded-language-understanding-in-a-collaborative-environment-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Dominik_drexler Expressing and Exploiting the Common Subgoal Structure of Classical Planning Domains Using Sketches 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Expressing and Exploiting the Common Subgoal Structure of Classical Planning Domains Using Sketches Author: Dominik Drexler et. al. Publish Year: 2021 Review Date: Dec 2021 Summary of paper Algorithms like SIW often fail when the goal is not easily serialisable or when some of the subproblems have a high width. In this work, the author address these limitations by using a simple but powerful language for expressing finer problem decompositions called policy sketches.
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-17 13:07:53 +1100 AEDT">December 17, 2021</span> · 3 min · Sukai Huang</footer>
<a aria-label="post link to Dominik_drexler Expressing and Exploiting the Common Subgoal Structure of Classical Planning Domains Using Sketches 2021" class="entry-link" href="http://localhost:1313/posts/dominik_drexler-expressing-and-exploiting-the-common-subgoal-structure-of-classical-planning-domains-using-sketches-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Yiding_jiang Language as Abstraction for Hierarchical Deep Reinforcement Learning
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Language as an Abstraction for Hierarchical Deep Reinforcement Learning Author: Yiding Jiang et. al. Publish Year: 2019 NeurIPS Review Date: Dec 2021 Summary of paper Solving complex, temporally-extended tasks is a long-standing problem in RL.
Acquiring effective yet general abstractions for hierarchical RL is remarkably challenging.
Therefore, they propose to use language as the abstraction, as it provides unique compositional structure, enabling fast learning and combinatorial generalisation
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-15 19:49:28 +1100 AEDT">December 15, 2021</span> · 3 min · Sukai Huang</footer>
<a aria-label="post link to Yiding_jiang Language as Abstraction for Hierarchical Deep Reinforcement Learning" class="entry-link" href="http://localhost:1313/posts/yiding_jiang-language-as-abstraction-for-hierarchical-deep-reinforcement-learning/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Hengyuan_hu Hierarchical Decision Making by Generating and Following Natural Language Instructions 2019
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Hierarchical Decision Making by Generating and Following Natural Language Instructions Author: Hengyuan Hu et. al. FAIR Publish Year: 2019 Review Date: Dec 2021 Summary of paper One line summary: they build a Architect Builder model to clone human behaviour for playing RTS game
Their task environment is very similar to IGLU competition setting, but their model is too task-specific
The author mentioned some properties about natural language instructions
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-15 13:11:05 +1100 AEDT">December 15, 2021</span> · 2 min · Sukai Huang</footer>
<a aria-label="post link to Hengyuan_hu Hierarchical Decision Making by Generating and Following Natural Language Instructions 2019" class="entry-link" href="http://localhost:1313/posts/hengyuan_hu-hierarchical-decision-making-by-generating-and-following-natural-language-instructions-2019/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">David_ding Attention Over Learned Object Embeddings Enables Complex Visual Reasoning 2021
    </h2>
</header>
<div class="entry-content">
<p> Title: Attention Over Learned Object Embeddings Enables Complex Visual Reasoning Author: David Ding et. al. Publish Year: 2021 NeurIPS Review Date: Dec 2021 Background info for this paper:
Their paper propose a all-in-one transformer model that is able to answer CLEVRER counterfactual questions with higher accuracy (75.6% vs 46.5%) and less training data (- 40%)
They believe that their model relies on three key aspects:
self-attention soft-discretization self-supervised learning ...</p>
</div>
<footer class="entry-footer"><span title="2021-12-15 12:59:07 +1100 AEDT">December 15, 2021</span> · 3 min · Sukai Huang</footer>
<a aria-label="post link to David_ding Attention Over Learned Object Embeddings Enables Complex Visual Reasoning 2021" class="entry-link" href="http://localhost:1313/posts/david_ding-attention-over-learned-object-embeddings-enables-complex-visual-reasoning-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Jacob_andreas Modular Multitask Reinforcement Learning With Policy Sketches 2017
    </h2>
</header>
<div class="entry-content">
<p> Title: Modular Multitask Reinforcement Learning with Policy Sketches Author: Jacob Andreas et. al. Publish Year: 2017 Review Date: Dec 2021 Background info for this paper:
Their paper describe a framework that is inspired by on options MDP, for which a reinforcement learning task is handled by several sub-MDP modules. (that is why they call it Modular RL)
They consider a multitask RL problem in a shared environment. (See the figure below). The IGLU Minecraft challenge as well as Angry Birds also belongs to this category.
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-13 17:23:12 +1100 AEDT">December 13, 2021</span> · 3 min · Sukai Huang</footer>
<a aria-label="post link to Jacob_andreas Modular Multitask Reinforcement Learning With Policy Sketches 2017" class="entry-link" href="http://localhost:1313/posts/jacob_andreas-modular-multitask-reinforcement-learning-with-policy-sketches-2017/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">David_abel on the Expressivity of Markov Reward 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: On the Expressivity of Markov Reward Author: David Abel et. al. Publish Year: NuerIPS 2021 Review Date: 6 Dec 2021 Summary of paper This needs to be only 1-3 sentences, but it demonstrates that you understand the paper and, moreover, can summarize it more concisely than the author in his abstract.
The author found out that in the Markov Decision Process scenario, (i.e., we do not look at the history of the trajectory to provide rewards), some tasks cannot be realised perfectly by reward functions. i.e.,
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-05 12:02:23 +1100 AEDT">December 5, 2021</span> · 5 min · Sukai Huang</footer>
<a aria-label="post link to David_abel on the Expressivity of Markov Reward 2021" class="entry-link" href="http://localhost:1313/posts/david_abel-on-the-expressivity-of-markov-reward-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Rishabh_agarwal Deep Reinforcement Learning at the Edge of the Stats Precipice 2021
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Deep Reinforcement Learning at the Edge of the Statistical Precipice Author: Rishabh Agarwal et. al. Publish Year: NeurIPS 2021 Review Date: 3 Dec 2021 Summary of paper This needs to be only 1-3 sentences, but it demonstrates that you understand the paper and, moreover, can summarize it more concisely than the author in his abstract.
Most current published results on deep RL benchmarks uses point estimate of aggregate performance such as mean and median score across the task.
...</p>
</div>
<footer class="entry-footer"><span title="2021-12-03 19:50:10 +1100 AEDT">December 3, 2021</span> · 3 min · Sukai Huang</footer>
<a aria-label="post link to Rishabh_agarwal Deep Reinforcement Learning at the Edge of the Stats Precipice 2021" class="entry-link" href="http://localhost:1313/posts/rishabh_agarwal-deep-reinforcement-learning-at-the-edge-of-the-stats-precipice-2021/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Borja_ibarz Reward Learning From Human Preferences and Demonstrations in Atari 2018
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Reward learning from human preferences and demonstractions in Atari Author: Borja Ibarz et. al. Publish Year: 2018 Review Date: Nov 2021 Summary of paper This needs to be only 1-3 sentences, but it demonstrates that you understand the paper and, moreover, can summarize it more concisely than the author in his abstract.
The author proposed a method that uses human expert’s annotation rather than extrinsic reward from the environment to guide the reinforcement learning.
...</p>
</div>
<footer class="entry-footer"><span title="2021-11-27 19:14:04 +1100 AEDT">November 27, 2021</span> · 2 min · Sukai Huang</footer>
<a aria-label="post link to Borja_ibarz Reward Learning From Human Preferences and Demonstrations in Atari 2018" class="entry-link" href="http://localhost:1313/posts/borja_ibarz-reward-learning-from-human-preferences-and-demonstrations-in-atari-2018/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Adrien_ecoffet Go Explore a New Approach for Hard Exploration Problems 2021 Paper Review
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Go-Explore: a New Approach for Hard-Exploration Problems Author: Adrien Ecoffet et. al. Publish Year: 2021 Review Date: Nov 2021 Summary of paper This needs to be only 1-3 sentences, but it demonstrates that you understand the paper and, moreover, can summarize it more concisely than the author in his abstract.
The author hypothesised that there are two main issues that prevent DRL agents from achieving high score in exploration-hard game (e.g., Montezuma’s Revenge)
...</p>
</div>
<footer class="entry-footer"><span title="2021-11-27 18:58:32 +1100 AEDT">November 27, 2021</span> · 4 min · Sukai Huang</footer>
<a aria-label="post link to Adrien_ecoffet Go Explore a New Approach for Hard Exploration Problems 2021 Paper Review" class="entry-link" href="http://localhost:1313/posts/adrien_ecoffet-go-explore-a-new-approach-for-hard-exploration-problems-2021-paper-review/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Tuomas_haarnoja Soft Actor Critic Off Policy Maximum Entropy Deep Reinforcement Learning With a Stochastic Actor 2018 Paper Review
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
[论文简析]SAC: Soft Actor-Critic Part 1[1801.01290] hat means estimation
</p>
</div>
<footer class="entry-footer"><span title="2021-11-18 12:08:53 +1100 AEDT">November 18, 2021</span> · 1 min · Sukai Huang</footer>
<a aria-label="post link to Tuomas_haarnoja Soft Actor Critic Off Policy Maximum Entropy Deep Reinforcement Learning With a Stochastic Actor 2018 Paper Review" class="entry-link" href="http://localhost:1313/posts/tuomas_haarnoja-soft-actor-critic-off-policy-maximum-entropy-deep-reinforcement-learning-with-a-stochastic-actor-2018-paper-review/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Adria Badia Agent57 Outperforming the Atari Human Benchmark 2020 Paper Review
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Agent57: Outperforming the Atari Human Benchmark 2020 Author: Adria Badia et. al. Publish Year: 2020 Review Date: Nov 2021 Summary of paper This needs to be only 1-3 sentences, but it demonstrates that you understand the paper and, moreover, can summarize it more concisely than the author in his abstract.
Agent57 is the SOTA Atari RL agent in 2020 that can play difficult Atari games like “Montezuma’s Revenge, “Pitfall”, “Solaris” and “Skiing”.
...</p>
</div>
<footer class="entry-footer"><span title="2021-11-18 12:05:47 +1100 AEDT">November 18, 2021</span> · 5 min · Sukai Huang</footer>
<a aria-label="post link to Adria Badia Agent57 Outperforming the Atari Human Benchmark 2020 Paper Review" class="entry-link" href="http://localhost:1313/posts/adria-badia-agent57-outperforming-the-atari-human-benchmark-2020-paper-review/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Stefan O Toole Width Based Lookaheads With Learnt Base Policies and Heuristics Over the Atari 2600 Benchmark 2021 Paper Reivew
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: Width-based Lookaheads with Learnt Base Policies and Heuristics Over the Atari-2600 Benchmark Author: Stefan O’Toole et. al. Publish Year: 2021 Review Date: Tue 16 Nov 2021 Summary of paper This needs to be only 1-3 sentences, but it demonstrates that you understand the paper and, moreover, can summarize it more concisely than the author in his abstract.
This paper proposed a new width-based planning and learning agent that can play Atari-2600 games (though it cannot play Montezuma’s Revenge). The author claimed that width-based planning exploration plus (greedy) optimal MDP policy exploitation is able to achieve better performance than Monte-Carlo Tree Search.
...</p>
</div>
<footer class="entry-footer"><span title="2021-11-16 17:40:10 +1100 AEDT">November 16, 2021</span> · 4 min · Sukai Huang</footer>
<a aria-label="post link to Stefan O Toole Width Based Lookaheads With Learnt Base Policies and Heuristics Over the Atari 2600 Benchmark 2021 Paper Reivew" class="entry-link" href="http://localhost:1313/posts/stefan-o-toole-width-based-lookaheads-with-learnt-base-policies-and-heuristics-over-the-atari-2600-benchmark-2021-paper-reivew/"></a>
</article>
<article class="post-entry">
<header class="entry-header">
<h2 class="entry-hint-parent">Cristian Paul Bara Mindcraft Theory of Mind Modelling 2021 Paper Review
    </h2>
</header>
<div class="entry-content">
<p>[TOC]
Title: MINDCRAFT: Theory of Mind Modeling for Situated Dialogue in Collaborative Tasks Author: Cristian-Paul Bara et. al. Publish Year: 2021 EMNLP Review Date: 12 Nov 2021 Summary of paper This needs to be only 1-3 sentences, but it demonstrates that you understand the paper and, moreover, can summarize it more concisely than the author in his abstract.
The contribution of this paper is the mind modelling dataset (Using Minecraft environment).
...</p>
</div>
<footer class="entry-footer"><span title="2021-11-12 12:56:24 +1100 AEDT">November 12, 2021</span> · 3 min · Sukai Huang</footer>
<a aria-label="post link to Cristian Paul Bara Mindcraft Theory of Mind Modelling 2021 Paper Review" class="entry-link" href="http://localhost:1313/posts/cristian-paul-bara-mindcraft-theory-of-mind-modelling-2021-paper-review/"></a>
</article>
<footer class="page-footer">
<nav class="pagination">
<a class="prev" href="http://localhost:1313/page/10/">
      « Prev 10/11
    </a>
</nav>
</footer>
</main>
<footer class="footer">
<span>© 2024 <a href="http://localhost:1313/">Sukai Huang</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &amp;
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
</span>
</footer>
<a accesskey="g" aria-label="go to top" class="top-link" href="#top" id="top-link" title="Go to Top (Alt + G)">
<svg fill="currentColor" viewbox="0 0 12 6" xmlns="http://www.w3.org/2000/svg">
<path d="M12 6H0l6-6z"></path>
</svg>
</a>
<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>
</html>
