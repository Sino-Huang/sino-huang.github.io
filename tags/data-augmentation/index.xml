<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Data Augmentation on Sukai Huang</title>
    <link>https://sino-huang.github.io/tags/data-augmentation/</link>
    <description>Recent content in Data Augmentation on Sukai Huang</description>
    <image>
      <title>Sukai Huang</title>
      <url>https://sino-huang.github.io/sukai_avatar.jpg</url>
      <link>https://sino-huang.github.io/sukai_avatar.jpg</link>
    </image>
    <generator>Hugo -- 0.140.2</generator>
    <language>en</language>
    <lastBuildDate>Fri, 10 Feb 2023 02:51:23 +1100</lastBuildDate>
    <atom:link href="https://sino-huang.github.io/tags/data-augmentation/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Xiwen_liang Contrastive Instruction Trajectory Learning for Vision Language Navigation 2022</title>
      <link>https://sino-huang.github.io/posts/xiwen_liang-contrastive-instruction-trajectory-learning-for-vision-language-navigation-2022/</link>
      <pubDate>Fri, 10 Feb 2023 02:51:23 +1100</pubDate>
      <guid>https://sino-huang.github.io/posts/xiwen_liang-contrastive-instruction-trajectory-learning-for-vision-language-navigation-2022/</guid>
      <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Title:  Contrastive Instruction Trajectory Learning for Vision Language Navigation&lt;/li&gt;
&lt;li&gt;Author: Xiwen Liang et. al.&lt;/li&gt;
&lt;li&gt;Publish Year: AAAI 2022&lt;/li&gt;
&lt;li&gt;Review Date: Fri, Feb 10, 2023&lt;/li&gt;
&lt;li&gt;url: &lt;a href=&#34;https://arxiv.org/abs/2112.04138&#34;&gt;https://arxiv.org/abs/2112.04138&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;summary-of-paper&#34;&gt;Summary of paper&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&#34;image-20230210025151701&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/xiwen_liang-contrastive-instruction-trajectory-learning-for-vision-language-navigation-2022/image-assets/cover.png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;previous works learn to navigate step-by-step following an instruction. However, these works may fail to discriminate the similarities and discrepancies across instruction-trajectory pairs and ignore the &lt;strong&gt;&lt;u&gt;temporal continuity&lt;/u&gt;&lt;/strong&gt; of sub-instructions. These problems hinder agents from learning distinctive vision-and-language representations,&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;contribution&#34;&gt;Contribution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;we propose
&lt;ul&gt;
&lt;li&gt;a coarse-grained &lt;strong&gt;contrastive learning&lt;/strong&gt; objective  to enhance vision-and-language representations by &lt;u&gt;contrasting semantics of full trajectory observations&lt;/u&gt; and instructions respectively;&lt;/li&gt;
&lt;li&gt;a fine-grained contrastive learning objective to perceive instructions by leveraging the &lt;u&gt;temporal information&lt;/u&gt; of the sub-instructions.&lt;/li&gt;
&lt;li&gt;a pairwise sample-reweighting mechanism for contrastive learning to sampling bias in contrastive learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;some-key-terms&#34;&gt;Some key terms&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Limitation of current VLN model&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ekin_akyurek Towards Tracing Factual Knowledge in Language Models Back to the Training Data 2022</title>
      <link>https://sino-huang.github.io/posts/ekin_akyurek-towards-tracing-factual-knowledge-in-language-models-back-to-the-training-data-2022/</link>
      <pubDate>Wed, 08 Feb 2023 22:16:28 +1100</pubDate>
      <guid>https://sino-huang.github.io/posts/ekin_akyurek-towards-tracing-factual-knowledge-in-language-models-back-to-the-training-data-2022/</guid>
      <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Title: Towards Tracing Factual Knowledge in Language Models Back to the Training Data&lt;/li&gt;
&lt;li&gt;Author: Ekin Akyurek et. al.&lt;/li&gt;
&lt;li&gt;Publish Year: EMNLP 2022&lt;/li&gt;
&lt;li&gt;Review Date: Wed, Feb 8, 2023&lt;/li&gt;
&lt;li&gt;url: &lt;a href=&#34;https://aclanthology.org/2022.findings-emnlp.180.pdf&#34;&gt;https://aclanthology.org/2022.findings-emnlp.180.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;summary-of-paper&#34;&gt;Summary of paper&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&#34;image-20230209232944264&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/ekin_akyurek-towards-tracing-factual-knowledge-in-language-models-back-to-the-training-data-2022/image-assets/cover.png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;LMs have been shown to memorize a great deal of factual knowledge contained in their training data. But when an LM generates an assertion, it is often difficult to determine where it learned this information and whether it is true.&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&#34;image-assets/image-20230210000202731.png&#34; alt=&#34;image-20230210000202731&#34; style=&#34;width:70%;&#34; /&gt;
&lt;h3 id=&#34;contribution&#34;&gt;Contribution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;we propose the problem of fact tracing
&lt;ul&gt;
&lt;li&gt;identifying which training examples taught an LM to generate a particular factual assertion.&lt;/li&gt;
&lt;li&gt;prior work on training data distribution (TDA) may offer effective tools for identifying such examples, known as &amp;ldquo;proponent&amp;rdquo;. We present the first quantitative benchmark to evaluate this&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;we compare two popular families of TDA methods
&lt;ul&gt;
&lt;li&gt;gradient based&lt;/li&gt;
&lt;li&gt;embedding based&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;some-key-terms&#34;&gt;Some key terms&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Training data distribution method (TDA)&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
