<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Contrastive Learning on Sukai Huang</title>
    <link>https://sino-huang.github.io/tags/contrastive-learning/</link>
    <description>Recent content in Contrastive Learning on Sukai Huang</description>
    <image>
      <title>Sukai Huang</title>
      <url>https://sino-huang.github.io/sukai_avatar.jpg</url>
      <link>https://sino-huang.github.io/sukai_avatar.jpg</link>
    </image>
    <generator>Hugo -- 0.140.2</generator>
    <language>en</language>
    <lastBuildDate>Fri, 10 Feb 2023 02:51:23 +1100</lastBuildDate>
    <atom:link href="https://sino-huang.github.io/tags/contrastive-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Xiwen_liang Contrastive Instruction Trajectory Learning for Vision Language Navigation 2022</title>
      <link>https://sino-huang.github.io/posts/xiwen_liang-contrastive-instruction-trajectory-learning-for-vision-language-navigation-2022/</link>
      <pubDate>Fri, 10 Feb 2023 02:51:23 +1100</pubDate>
      <guid>https://sino-huang.github.io/posts/xiwen_liang-contrastive-instruction-trajectory-learning-for-vision-language-navigation-2022/</guid>
      <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Title:  Contrastive Instruction Trajectory Learning for Vision Language Navigation&lt;/li&gt;
&lt;li&gt;Author: Xiwen Liang et. al.&lt;/li&gt;
&lt;li&gt;Publish Year: AAAI 2022&lt;/li&gt;
&lt;li&gt;Review Date: Fri, Feb 10, 2023&lt;/li&gt;
&lt;li&gt;url: &lt;a href=&#34;https://arxiv.org/abs/2112.04138&#34;&gt;https://arxiv.org/abs/2112.04138&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;summary-of-paper&#34;&gt;Summary of paper&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&#34;image-20230210025151701&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/xiwen_liang-contrastive-instruction-trajectory-learning-for-vision-language-navigation-2022/image-assets/cover.png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;previous works learn to navigate step-by-step following an instruction. However, these works may fail to discriminate the similarities and discrepancies across instruction-trajectory pairs and ignore the &lt;strong&gt;&lt;u&gt;temporal continuity&lt;/u&gt;&lt;/strong&gt; of sub-instructions. These problems hinder agents from learning distinctive vision-and-language representations,&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;contribution&#34;&gt;Contribution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;we propose
&lt;ul&gt;
&lt;li&gt;a coarse-grained &lt;strong&gt;contrastive learning&lt;/strong&gt; objective  to enhance vision-and-language representations by &lt;u&gt;contrasting semantics of full trajectory observations&lt;/u&gt; and instructions respectively;&lt;/li&gt;
&lt;li&gt;a fine-grained contrastive learning objective to perceive instructions by leveraging the &lt;u&gt;temporal information&lt;/u&gt; of the sub-instructions.&lt;/li&gt;
&lt;li&gt;a pairwise sample-reweighting mechanism for contrastive learning to sampling bias in contrastive learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;some-key-terms&#34;&gt;Some key terms&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Limitation of current VLN model&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Yung_sung_chuang Diffcse Difference Based Contrastive Learning for Sentence Embeddings 2022</title>
      <link>https://sino-huang.github.io/posts/yung_sung_chuang-diffcse-difference-based-contrastive-learning-for-sentence-embeddings-2022/</link>
      <pubDate>Sat, 27 Aug 2022 16:03:42 +1000</pubDate>
      <guid>https://sino-huang.github.io/posts/yung_sung_chuang-diffcse-difference-based-contrastive-learning-for-sentence-embeddings-2022/</guid>
      <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Title: DiffCSE: Difference Based Contrastive Learning for Sentence Embeddings&lt;/li&gt;
&lt;li&gt;Author: Yung-Sung Chuang et. al.&lt;/li&gt;
&lt;li&gt;Publish Year: 21 Apr 2022&lt;/li&gt;
&lt;li&gt;Review Date: Sat, Aug 27, 2022&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;summary-of-paper&#34;&gt;Summary of paper&lt;/h2&gt;
&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;DiffCSE learns sentences that are sensitive to the difference between the original sentence and and &lt;strong&gt;edited sentence&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;contribution&#34;&gt;Contribution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;we propose DiffCSE, an unsupervised contrastive learning framework for learning &lt;strong&gt;sentence embeddings&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;some-key-terms&#34;&gt;Some key terms&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;DiffCSE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;this is an unsupervsied contrastive learning framework rather than model architecture&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Contrastive learning in single modality data&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
