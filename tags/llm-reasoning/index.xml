<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Llm Reasoning on Sukai Huang</title>
    <link>https://sino-huang.github.io/tags/llm-reasoning/</link>
    <description>Recent content in Llm Reasoning on Sukai Huang</description>
    <image>
      <title>Sukai Huang</title>
      <url>https://sino-huang.github.io/sukai_avatar.jpg</url>
      <link>https://sino-huang.github.io/sukai_avatar.jpg</link>
    </image>
    <generator>Hugo -- 0.140.2</generator>
    <language>en</language>
    <lastBuildDate>Sun, 09 Feb 2025 21:07:11 +1100</lastBuildDate>
    <atom:link href="https://sino-huang.github.io/tags/llm-reasoning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Awesome LLMs Reasoning Abilities Papers</title>
      <link>https://sino-huang.github.io/posts/awesome_llm_reasoning_capability_papers/</link>
      <pubDate>Sun, 09 Feb 2025 21:07:11 +1100</pubDate>
      <guid>https://sino-huang.github.io/posts/awesome_llm_reasoning_capability_papers/</guid>
      <description>&lt;h3 id=&#34;demystifying-long-chain-of-thought-reasoning-in-llms&#34;&gt;Demystifying Long Chain-of-Thought Reasoning in LLMs&lt;/h3&gt;
&lt;p&gt;This study systematically investigate the mechanics of long CoT reasoning,  identifying the key factors that enable models to generate long CoT  trajectories and providing practical guidance for optimizing training  strategies to enhance long CoT reasoning in LLMs&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2502.03373.pdf&#34;&gt;https://arxiv.org/pdf/2502.03373.pdf&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning&#34;&gt;DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning&lt;/h3&gt;
&lt;p&gt;This work introduces first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1, which incorporates multi-stage training and cold-start  data before RL and achieves performance comparable to OpenAI-o1-1217 on  reasoning tasks.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
